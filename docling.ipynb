{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6bc954c",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a79355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 studies which are already processed.\n",
      "Studies which STILL need to be processed: 0:\n",
      "[]...\n"
     ]
    }
   ],
   "source": [
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import hashlib\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.rerankers import ColbertReranker\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import re, unicodedata\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def clean_docling_chunk_strings(chunks):\n",
    "    cleaned_chunks = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # 2️⃣ Normalize Unicode and replace problematic punctuation\n",
    "        chunk = unicodedata.normalize(\"NFKD\", chunk).replace(\"\\u00A0\", \" \")\n",
    "        chunk = chunk.translate(str.maketrans({\n",
    "            \"–\": \"-\", \"—\": \"-\", \"‘\": \"'\", \"’\": \"'\", \"“\": '\"', \"”\": '\"'\n",
    "        }))\n",
    "\n",
    "        # 3️⃣ Remove URLs (massive tokenizers killers)\n",
    "        chunk = re.sub(r\"http\\S+\", \"\", chunk)\n",
    "\n",
    "        # 4️⃣ Normalize whitespace but preserve paragraphs\n",
    "        chunk = re.sub(r\"[ \\t]+\", \" \", chunk)\n",
    "        chunk = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", chunk)  # merge single newlines, keep double\n",
    "        chunk = chunk.strip()\n",
    "\n",
    "        cleaned_chunks.append(chunk)\n",
    "\n",
    "    return cleaned_chunks\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"nomic-ai/nomic-embed-text-v1.5\"\n",
    "MAX_TOKENS = 2000\n",
    "OLLAMA_MODEL_NAME= \"chunker_full_doc\"\n",
    "CHUNKS_WITH_METADATA_FILE_NAME = \"sliding_chunks_with_metadata.json\"\n",
    "INPUT_DIR = \"input\"\n",
    "\n",
    "\n",
    "converter = DocumentConverter()\n",
    "tokenizer = HuggingFaceTokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME),\n",
    "    max_tokens=MAX_TOKENS # Optional, uses the max token number of the HF tokenizer by default\n",
    ")\n",
    "chunker = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    merge_peers=True #Optional, defaults to true\n",
    ")\n",
    "\n",
    "study_names = [f for f in os.listdir(INPUT_DIR) if f.endswith('.pdf')]\n",
    "processed_chunks=[]\n",
    "try:\n",
    "    with open(CHUNKS_WITH_METADATA_FILE_NAME, \"r\", encoding=\"utf-8\") as f:\n",
    "        processed_chunks = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"No existing {CHUNKS_WITH_METADATA_FILE_NAME} file found, starting fresh.\")\n",
    "    \n",
    "\n",
    "chunks_with_metadata = processed_chunks.copy()\n",
    "processed_studies = set(chunk[\"document\"] for chunk in processed_chunks)\n",
    "\n",
    "study_names = [f for f in study_names if f not in processed_studies]\n",
    "print(f\"Found {len(processed_studies)} studies which are already processed.\\nStudies which STILL need to be processed: {len(study_names)}:\\n{study_names}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average chunk token count in different categories of documents\n",
      "Tobacco: \t\t420.94444444444446\n",
      "Scientific papers:\t663.5811518324607\n"
     ]
    }
   ],
   "source": [
    "with open(\"tobacco_sliding_chunks_with_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        tobacco_chunks = json.load(f)\n",
    "\n",
    "with open(\"sliding_chunks_with_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        scientific_chunks = json.load(f)\n",
    "\n",
    "tobacco_chunks = [chunk['original_text'] for chunk in tobacco_chunks]\n",
    "scientific_chunks = [chunk['original_text'] for chunk in scientific_chunks]\n",
    "\n",
    "tobacco_chunk_token_length = [len(tokenizer.tokenizer.tokenize(chunk)) for chunk in tobacco_chunks]\n",
    "scientific_chunk_token_length = [len(tokenizer.tokenizer.tokenize(chunk)) for chunk in scientific_chunks]\n",
    "\n",
    "import numpy as np\n",
    "print(f\"Average chunk token count in different categories of documents\\nTobacco: \\t\\t{np.mean(np.array(tobacco_chunk_token_length))}\\nScientific papers:\\t{np.mean(np.array(scientific_chunk_token_length))}\")\n",
    "\n",
    "# PREVIOUS VALUES\n",
    "# Average chunk token count in different categories of documents\n",
    "# Tobacco: \t\t420.94444444444446\n",
    "# Scientific papers:\t671.1837270341207\n",
    "\n",
    "# VALUES WITH NEW ALGORITHM ON SCIENTIFIC PAPERS\n",
    "# Average chunk token count in different categories of documents\n",
    "# Tobacco: \t\t420.94444444444446\n",
    "# Scientific papers:\t663.5811518324607"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508b299",
   "metadata": {},
   "source": [
    "# Creating chunks and adding Metadata\n",
    "\n",
    "As well as semantic context with ollama (Anthropic style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df465975",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in tqdm(study_names, desc=\"Chunking documents...\"):        \n",
    "    entire_doc = \"\"\n",
    "    doc = converter.convert(f\"{INPUT_DIR}/{source}\").document\n",
    "    chunks = list(chunker.chunk(dl_doc=doc))\n",
    "    chunks_str = [chunk.text for chunk in chunks]\n",
    "    chunks_str = clean_docling_chunk_strings(chunks_str)\n",
    "\n",
    "    # Free up CUDA memory right after we got the results from Docling, so that Ollama can use the entire GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    for chunk in tqdm(chunks, desc=f\"Adding context for chunks of {source[:20]}...\", leave=False):    \n",
    "        entire_doc = \"\"\n",
    "        chunk_index = chunks.index(chunk)\n",
    "\n",
    "        context_length = 16_000 # Reduce window to save memory\n",
    "        context_length = context_length - 2 * MAX_TOKENS # We need to reserve space for the chunk itself (twice, the context contains the chunk itself)\n",
    "        total_context_chunk_number = context_length // (MAX_TOKENS*2) # 2x, cuz before and after the chunk\n",
    "\n",
    "        start_index_original = chunk_index - total_context_chunk_number\n",
    "        start_index_truncated = max(0, start_index_original) # Avoid index out of bounds\n",
    "\n",
    "        end_index_original = chunk_index + total_context_chunk_number\n",
    "        end_index_truncated = min(len(chunks)-1, end_index_original)\n",
    "\n",
    "        if start_index_original < 0: # We are at the start of the document, so we need to add more chunks at the end\n",
    "            end_index_truncated = min(len(chunks)-1, end_index_truncated + abs(start_index_original))\n",
    "        if end_index_original > len(chunks)-1: # We are at the end of the document, so we need to add more chunks at the start\n",
    "            start_index_truncated = max(0, start_index_truncated - abs(end_index_original - end_index_truncated))\n",
    "\n",
    "        for i in range(start_index_truncated, end_index_truncated + 1):\n",
    "            entire_doc += \" \" + chunks_str[i]\n",
    "\n",
    "        entire_doc = \"FULL DOCUMENT:\\n\" + entire_doc\n",
    "        ollama_prompt = f\"CHUNK:\\n{chunks_str[chunk_index]}\"\n",
    "        history =  [{'role': 'user', 'content': entire_doc}, {'role': 'user', 'content': ollama_prompt}]\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL_NAME,\n",
    "            messages=history,\n",
    "            # options={\n",
    "            #     'gpu_layers': 100  # use  GPU for model layers if VRAM allows\n",
    "            # }\n",
    "        )\n",
    "        context = response['message']['content']\n",
    "        # print(f\"Context for chunk: {context}\")\n",
    "        # ---- OWN APPROACH TO CONTEXT ----\n",
    "        # text_to_embed = chunks_str[chunk_index] + \"\\n\\n\" + context # We put the context AFTER the chunk to not mess up cosine similarity but still benefit keyword search for exact matches\n",
    "\n",
    "        # ---- ANTHROPIC'S APPROACH TO CONTEXT ----\n",
    "        text_to_embed = context + \"\\n\\n\" + chunks_str[chunk_index] # The context is PREPENDED to the chunk as per Anthropic's original algporithm\n",
    "        # print(context)\n",
    "        pages = set(\n",
    "                prov.page_no\n",
    "                for doc_item in chunk.meta.doc_items\n",
    "                for prov in doc_item.prov\n",
    "            )\n",
    "        id = hashlib.sha256(chunks_str[chunk_index].encode()).hexdigest()\n",
    "        chunks_with_metadata.append({'text': text_to_embed, 'original_text':chunks_str[chunk_index], 'context':context, 'document':source, 'pages':list(pages), 'id': id})\n",
    "        \n",
    "    # Free up ollama from GPU memory so that Docling can semantically analyze the next doc even if it's like 100 pages\n",
    "    subprocess.run([\"ollama\", \"stop\", OLLAMA_MODEL_NAME], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7b3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to sliding_chunks_with_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save the the processed chunks in case VectorDB upload goes wrong.\n",
    "# Luckily since this is a notebook, if the chunking is interrupted, we can still save the partial results here.\n",
    "# Append new chunks to the existing file if it exists, otherwise create it\n",
    "if os.path.exists(CHUNKS_WITH_METADATA_FILE_NAME):\n",
    "    print(f\"Appending to existing {CHUNKS_WITH_METADATA_FILE_NAME} file.\")\n",
    "    with open(CHUNKS_WITH_METADATA_FILE_NAME, \"r\", encoding=\"utf-8\") as f:\n",
    "        existing_data = json.load(f)\n",
    "    # Avoid duplicate entries by id\n",
    "    existing_ids = {chunk['id'] for chunk in existing_data}\n",
    "    new_chunks = [chunk for chunk in chunks_with_metadata if chunk['id'] not in existing_ids]\n",
    "    chunks_with_metadata = existing_data + new_chunks\n",
    "\n",
    "with open(CHUNKS_WITH_METADATA_FILE_NAME, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks_with_metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Results saved to {CHUNKS_WITH_METADATA_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65210f0f",
   "metadata": {},
   "source": [
    "# REORDER CONTEXT AND CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVENIENCE STEP: Prepare the chunks with metadata file for Anthropic's original approach (context PREPENDED to chunk)\n",
    "# # CHUNKS_WITH_METADATA_FILE_NAME = \"tobacco_sliding_chunks_with_metadata.json\"\n",
    "# # if os.path.exists(CHUNKS_WITH_METADATA_FILE_NAME):\n",
    "# #     with open(CHUNKS_WITH_METADATA_FILE_NAME, \"r\", encoding=\"utf-8\") as f:\n",
    "# #         chunks_with_metadata = json.load(f)\n",
    "\n",
    "# #     for chunk in chunks_with_metadata:\n",
    "# #         chunk['text'] = chunk['context'] + \"\\n\\n\" + chunk['original_text']\n",
    "\n",
    "# #     with open(f\"anthropic_{CHUNKS_WITH_METADATA_FILE_NAME}\", \"w\", encoding=\"utf-8\") as f:\n",
    "# #         json.dump(chunks_with_metadata, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9490cd2",
   "metadata": {},
   "source": [
    "# Creating Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7aa3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "\u001b[90m[\u001b[0m2026-01-04T16:41:20Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /home/martin/projects/Quantwise/Quantwise-Chunking/db/my_anthropic_sliding_tobacco_table.lance, it will be created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc2697c36344ef08524fa8061898646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading chunks to VectorDB:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ColBERTRanker model colbert-ir/colbertv2.0 (this message can be suppressed by setting verbose=0)\n",
      "No device set\n",
      "Using device cuda\n",
      "No dtype set\n",
      "Using dtype torch.float32\n",
      "Loading model colbert-ir/colbertv2.0, this might take a while...\n",
      "Linear Dim set to: 128 for downcasting\n"
     ]
    }
   ],
   "source": [
    "registry = get_registry()\n",
    "hf = registry.get(\"huggingface\").create(name=EMBEDDING_MODEL_NAME, trust_remote_code=True, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define model\n",
    "class MyDocument(LanceModel):\n",
    "    text: str = hf.SourceField()\n",
    "    vector: Vector(hf.ndims()) = hf.VectorField()\n",
    "    original_text: str\n",
    "    context: str\n",
    "    document: str\n",
    "    pages: list[int]  # Any additional metadata\n",
    "    id: str  # Unique identifier for the chunk\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"./db\")\n",
    "db.create_table(\"my_anthropic_sliding_tobacco_table\", schema=MyDocument, mode=\"overwrite\") # Uncomment this line when running this cell for the first time\n",
    "table = db.open_table(\"my_anthropic_sliding_tobacco_table\")\n",
    "\n",
    "# Upload in batches with progress bar\n",
    "with open(CHUNKS_WITH_METADATA_FILE_NAME, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_with_metadata = json.load(f)\n",
    "\n",
    "batch_size = 100\n",
    "for i in tqdm(range(0, len(chunks_with_metadata), batch_size), desc=\"Uploading chunks to VectorDB\"):\n",
    "    batch = chunks_with_metadata[i:i+batch_size]\n",
    "    table.add(batch)\n",
    "\n",
    "table.create_scalar_index(\"id\", replace=True) # Index based on the chunk's id, used to manually prevent duplicates\n",
    "\n",
    "reranker = ColbertReranker()\n",
    "table.create_fts_index(\"text\", replace=True) # Used by the reranker as well as the hybrid search's BM25 index\n",
    "table.wait_for_index([\"text_idx\"])  # Wait for the indexing to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3357c7",
   "metadata": {},
   "source": [
    "# Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42b9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>original_text</th>\n",
       "      <th>context</th>\n",
       "      <th>document</th>\n",
       "      <th>pages</th>\n",
       "      <th>id</th>\n",
       "      <th>_relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Details the collection and organization of dat...</td>\n",
       "      <td>[0.8555312, 1.101829, -3.8134143, -0.13130203,...</td>\n",
       "      <td>We collected stock market-related information ...</td>\n",
       "      <td>Details the collection and organization of dat...</td>\n",
       "      <td>Stock_Market_Prediction_via_Multi-Source_Multi...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>4cf733a743ce1b6eb4e3c41e23b999ed51cd3d280449ef...</td>\n",
       "      <td>1.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provides a detailed methodology for stock mark...</td>\n",
       "      <td>[0.6753454, 0.95625216, -2.8495104, -0.5628190...</td>\n",
       "      <td>Experimental design. Our paper relates to rese...</td>\n",
       "      <td>Provides a detailed methodology for stock mark...</td>\n",
       "      <td>s41598-020-77823-3.pdf</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>4eecb9240c936f76259c30feaf4292800c84483b696ec2...</td>\n",
       "      <td>0.983982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This chunk introduces the multi-source data in...</td>\n",
       "      <td>[0.2004797, 1.7068079, -3.6609893, -0.33517683...</td>\n",
       "      <td>Stock markets are impacted by various factors,...</td>\n",
       "      <td>This chunk introduces the multi-source data in...</td>\n",
       "      <td>Stock_Market_Prediction_via_Multi-Source_Multi...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>39c825d2635eebb324ba7686fde1bb602ed93eea99b7c3...</td>\n",
       "      <td>0.859257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Details the collection and organization of dat...   \n",
       "1  Provides a detailed methodology for stock mark...   \n",
       "2  This chunk introduces the multi-source data in...   \n",
       "\n",
       "                                              vector  \\\n",
       "0  [0.8555312, 1.101829, -3.8134143, -0.13130203,...   \n",
       "1  [0.6753454, 0.95625216, -2.8495104, -0.5628190...   \n",
       "2  [0.2004797, 1.7068079, -3.6609893, -0.33517683...   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  We collected stock market-related information ...   \n",
       "1  Experimental design. Our paper relates to rese...   \n",
       "2  Stock markets are impacted by various factors,...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Details the collection and organization of dat...   \n",
       "1  Provides a detailed methodology for stock mark...   \n",
       "2  This chunk introduces the multi-source data in...   \n",
       "\n",
       "                                            document   pages  \\\n",
       "0  Stock_Market_Prediction_via_Multi-Source_Multi...     [6]   \n",
       "1                             s41598-020-77823-3.pdf  [4, 5]   \n",
       "2  Stock_Market_Prediction_via_Multi-Source_Multi...     [3]   \n",
       "\n",
       "                                                  id  _relevance_score  \n",
       "0  4cf733a743ce1b6eb4e3c41e23b999ed51cd3d280449ef...          1.001428  \n",
       "1  4eecb9240c936f76259c30feaf4292800c84483b696ec2...          0.983982  \n",
       "2  39c825d2635eebb324ba7686fde1bb602ed93eea99b7c3...          0.859257  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How was stock market data gathered?\"\n",
    "results = table.search(prompt, query_type=\"hybrid\", vector_column_name=\"vector\", fts_columns=\"text\") \\\n",
    "            .rerank(reranker=reranker) \\\n",
    "            .limit(3) \\\n",
    "            .to_pandas()\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190f09d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We collected stock market-related information from Jan. 1, 2015 to Dec. 31, 2016, and separate the information into two data sets, one for the year 2015 and the other for 2016. The data consist of three parts, the historical quantitative data, the news articles and the posts on the social network, which are introduced in detail as follows.\\n- GLYPH<15> Quantitative data : the source of quantitative data is Wind, 2 a widely used GLYPH<28>nancial information service provider in China. The data we collect are the average prices, market index change and turnover rate of the Shanghai Composite Index in each trading day.\\n- GLYPH<15> News data : we collect the news articles on the macro economy through Wind, and get 38,727 and 39,465 news articles in 2015 and 2016 respectively. The news articles are aggregated by Wind from major GLYPH<28>nancial news websites in China, such as and We process the news titles rather than the whole articles to extract the events, as the main topic of a news article is often summed up in the title.\\n- GLYPH<15> Social media data : the sentiments are extracted from the posts crawled from a popular investor social network in China named Xueqiu. 3 Totally 6,163,056 postings are collected for 2015 and 2016. For each post, we get the posting time stamp and the content.\\nFor each trading day, if the stock market index rises, it would be a positive instance, otherwise it is a negative instance. For each year, we use the data from the GLYPH<28>rst 10 months as the training set and the last 2 months as the testing set. We evaluate the performance of our model with varying lead days and varying historical days. Lead days refers to the number of days in advance the model makes predictions and the historical days indicates the number of days over which the multi-source information is utilized. The evaluation metrics we use are F1-score and accuracy (ACC).\\n\\nDetails the collection and organization of data sources (quantitative, news, and social media) used for stock market prediction analysis, including the timeframe, data volume, and the method of extracting relevant information (e.g., news titles vs. full articles).'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25663f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_bytes': 3504703,\n",
       " 'num_rows': 382,\n",
       " 'num_indices': 2,\n",
       " 'fragment_stats': {'num_fragments': 4,\n",
       "  'num_small_fragments': 4,\n",
       "  'lengths': {'min': 82,\n",
       "   'max': 100,\n",
       "   'mean': 95,\n",
       "   'p25': 100,\n",
       "   'p50': 100,\n",
       "   'p75': 100,\n",
       "   'p99': 100}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantwise-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
