{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6bc954c",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a79355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 studies which are already processed.\n",
      "Studies which STILL need to be processed: 0:\n",
      "[]...\n"
     ]
    }
   ],
   "source": [
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import hashlib\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.rerankers import ColbertReranker\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import re, unicodedata\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def clean_docling_chunk_strings(chunks):\n",
    "    cleaned_chunks = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # 2️⃣ Normalize Unicode and replace problematic punctuation\n",
    "        chunk = unicodedata.normalize(\"NFKD\", chunk).replace(\"\\u00A0\", \" \")\n",
    "        chunk = chunk.translate(str.maketrans({\n",
    "            \"–\": \"-\", \"—\": \"-\", \"‘\": \"'\", \"’\": \"'\", \"“\": '\"', \"”\": '\"'\n",
    "        }))\n",
    "\n",
    "        # 3️⃣ Remove URLs (massive tokenizers killers)\n",
    "        chunk = re.sub(r\"http\\S+\", \"\", chunk)\n",
    "\n",
    "        # 4️⃣ Normalize whitespace but preserve paragraphs\n",
    "        chunk = re.sub(r\"[ \\t]+\", \" \", chunk)\n",
    "        chunk = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", chunk)  # merge single newlines, keep double\n",
    "        chunk = chunk.strip()\n",
    "\n",
    "        cleaned_chunks.append(chunk)\n",
    "\n",
    "    return cleaned_chunks\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"nomic-ai/nomic-embed-text-v1.5\"\n",
    "MAX_TOKENS = 2000\n",
    "OLLAMA_MODEL_NAME= \"chunker_full_doc\"\n",
    "\n",
    "converter = DocumentConverter()\n",
    "tokenizer = HuggingFaceTokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME),\n",
    "    max_tokens=MAX_TOKENS # Optional, uses the max token number of the HF tokenizer by default\n",
    ")\n",
    "chunker = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    merge_peers=True #Optional, defaults to true\n",
    ")\n",
    "\n",
    "input_dir = \"smoking/policy\"\n",
    "study_names = [f for f in os.listdir(input_dir) if f.endswith('.pdf')]\n",
    "chunks_with_metadata_file_name = \"tobacco_sliding_chunks_with_metadata.json\"\n",
    "processed_chunks=[]\n",
    "try:\n",
    "    with open(chunks_with_metadata_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        processed_chunks = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"No existing {chunks_with_metadata_file_name} file found, starting fresh.\")\n",
    "    \n",
    "\n",
    "chunks_with_metadata = processed_chunks.copy()\n",
    "processed_studies = set(chunk[\"document\"] for chunk in processed_chunks)\n",
    "\n",
    "study_names = [f for f in study_names if f not in processed_studies]\n",
    "print(f\"Found {len(processed_studies)} studies which are already processed.\\nStudies which STILL need to be processed: {len(study_names)}:\\n{study_names}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508b299",
   "metadata": {},
   "source": [
    "# Creating chunks and adding Metadata\n",
    "\n",
    "As well as semantic context with ollama (Anthropic style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df465975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38554fb52dd4eafb4897583c8838d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking documents...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for source in tqdm(study_names, desc=\"Chunking documents...\"):        \n",
    "    entire_doc = \"\"\n",
    "    doc = converter.convert(f\"{input_dir}/{source}\").document\n",
    "    chunks = list(chunker.chunk(dl_doc=doc))\n",
    "    chunks_str = [chunk.text for chunk in chunks]\n",
    "    chunks_str = clean_docling_chunk_strings(chunks_str)\n",
    "\n",
    "    # Free up CUDA memory right after we got the results from Docling, so that Ollama can use the entire GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    for chunk in tqdm(chunks, desc=f\"Adding context for chunks of {source[:20]}...\", leave=False):    \n",
    "        entire_doc = \"\"\n",
    "        chunk_index = chunks.index(chunk)\n",
    "\n",
    "        context_length = 16_000 # Reduce window to save memory\n",
    "        context_length = context_length - 2 * MAX_TOKENS # We need to reserve space for the chunk itself (twice, the context contains the chunk itself)\n",
    "        total_context_chunk_number = context_length // (MAX_TOKENS*2) # 2x, cuz before and after the chunk\n",
    "\n",
    "        start_index_original = chunk_index - total_context_chunk_number\n",
    "        start_index_truncated = max(0, start_index_original) # Avoid index out of bounds\n",
    "\n",
    "        end_index_original = chunk_index + total_context_chunk_number\n",
    "        end_index_truncated = min(len(chunks)-1, end_index_original)\n",
    "\n",
    "        if start_index_original < 0: # We are at the start of the document, so we need to add more chunks at the end\n",
    "            end_index_truncated = min(len(chunks)-1, end_index_truncated + abs(start_index_original))\n",
    "        if end_index_original > len(chunks)-1: # We are at the end of the document, so we need to add more chunks at the start\n",
    "            start_index_truncated = max(0, start_index_truncated + abs(end_index_original - end_index_truncated))\n",
    "\n",
    "        for i in range(start_index_truncated, end_index_truncated + 1):\n",
    "            entire_doc += \" \" + chunks_str[i]\n",
    "\n",
    "        entire_doc = \"FULL DOCUMENT:\\n\" + entire_doc\n",
    "        ollama_prompt = f\"CHUNK:\\n{chunks_str[chunk_index]}\"\n",
    "        history =  [{'role': 'user', 'content': entire_doc}, {'role': 'user', 'content': ollama_prompt}]\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL_NAME,\n",
    "            messages=history,\n",
    "            # options={\n",
    "            #     'gpu_layers': 100  # use  GPU for model layers if VRAM allows\n",
    "            # }\n",
    "        )\n",
    "        context = response['message']['content']\n",
    "        # print(f\"Context for chunk: {context}\")\n",
    "        text_to_embed = chunks_str[chunk_index] + \"\\n\\n\" + context # We put the context AFTER the chunk to not mess up cosine similarity but still\n",
    "        # print(context)\n",
    "        pages = set(\n",
    "                prov.page_no\n",
    "                for doc_item in chunk.meta.doc_items\n",
    "                for prov in doc_item.prov\n",
    "            )\n",
    "        id = hashlib.sha256(chunks_str[chunk_index].encode()).hexdigest()\n",
    "        chunks_with_metadata.append({'text': text_to_embed, 'original_text':chunks_str[chunk_index], 'context':context, 'document':source, 'pages':list(pages), 'id': id})\n",
    "        \n",
    "    # Free up ollama from GPU memory so that Docling can semantically analyze the next doc even if it's like 100 pages\n",
    "    subprocess.run([\"ollama\", \"stop\", OLLAMA_MODEL_NAME], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7b3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to existing tobacco_sliding_chunks_with_metadata.json file.\n",
      "Results saved to tobacco_sliding_chunks_with_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save the the processed chunks in case VectorDB upload goes wrong.\n",
    "# Luckily since this is a notebook, if the chunking is interrupted, we can still save the partial results here.\n",
    "# Append new chunks to the existing file if it exists, otherwise create it\n",
    "if os.path.exists(chunks_with_metadata_file_name):\n",
    "    print(f\"Appending to existing {chunks_with_metadata_file_name} file.\")\n",
    "    with open(chunks_with_metadata_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        existing_data = json.load(f)\n",
    "    # Avoid duplicate entries by id\n",
    "    existing_ids = {chunk['id'] for chunk in existing_data}\n",
    "    new_chunks = [chunk for chunk in chunks_with_metadata if chunk['id'] not in existing_ids]\n",
    "    chunks_with_metadata = existing_data + new_chunks\n",
    "\n",
    "with open(chunks_with_metadata_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks_with_metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Results saved to {chunks_with_metadata_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9490cd2",
   "metadata": {},
   "source": [
    "# Creating Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7aa3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "\u001b[90m[\u001b[0m2025-10-12T18:00:26Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /home/martin/projects/Quantwise/Quantwise-Chunking/db/my_sliding_tobacco_table.lance, it will be created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d14c6a7bfc463d8d15af8ef0f17e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading chunks to VectorDB:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ColBERTRanker model colbert-ir/colbertv2.0 (this message can be suppressed by setting verbose=0)\n",
      "No device set\n",
      "Using device cuda\n",
      "No dtype set\n",
      "Using dtype torch.float32\n",
      "Loading model colbert-ir/colbertv2.0, this might take a while...\n",
      "Linear Dim set to: 128 for downcasting\n"
     ]
    }
   ],
   "source": [
    "registry = get_registry()\n",
    "hf = registry.get(\"huggingface\").create(name=EMBEDDING_MODEL_NAME, trust_remote_code=True, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define model\n",
    "class MyDocument(LanceModel):\n",
    "    text: str = hf.SourceField()\n",
    "    vector: Vector(hf.ndims()) = hf.VectorField()\n",
    "    original_text: str\n",
    "    context: str\n",
    "    document: str\n",
    "    pages: list[int]  # Any additional metadata\n",
    "    id: str  # Unique identifier for the chunk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"./db\")\n",
    "db.create_table(\"my_sliding_tobacco_table\", schema=MyDocument, mode=\"overwrite\") # Uncomment this line when running this cell for the first time\n",
    "table = db.open_table(\"my_sliding_tobacco_table\")\n",
    "\n",
    "# Upload in batches with progress bar\n",
    "with open(chunks_with_metadata_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_with_metadata = json.load(f)\n",
    "\n",
    "batch_size = 100\n",
    "for i in tqdm(range(0, len(chunks_with_metadata), batch_size), desc=\"Uploading chunks to VectorDB\"):\n",
    "    batch = chunks_with_metadata[i:i+batch_size]\n",
    "    table.add(batch)\n",
    "\n",
    "table.create_scalar_index(\"id\", replace=True) # Index based on the chunk's id, used to manually prevent duplicates\n",
    "\n",
    "reranker = ColbertReranker()\n",
    "table.create_fts_index(\"text\", replace=True) # Used by the reranker as well as the hybrid search's BM25 index\n",
    "table.wait_for_index([\"text_idx\"])  # Wait for the indexing to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3357c7",
   "metadata": {},
   "source": [
    "# Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42b9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>original_text</th>\n",
       "      <th>context</th>\n",
       "      <th>document</th>\n",
       "      <th>pages</th>\n",
       "      <th>id</th>\n",
       "      <th>_relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A rank rating test was used to assess the inte...</td>\n",
       "      <td>[-0.12656964, 0.45683643, -3.8943672, -1.77620...</td>\n",
       "      <td>A rank rating test was used to assess the inte...</td>\n",
       "      <td>Details the methodology for assessing whether ...</td>\n",
       "      <td>methodology_technical-assessment_test-products...</td>\n",
       "      <td>[21]</td>\n",
       "      <td>df5a96217dca6d7d6c5d976a18c9b98a7a79263efd8080...</td>\n",
       "      <td>1.140071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Because the term clearly noticeable has no spe...</td>\n",
       "      <td>[0.7338957, -0.12551239, -3.632481, -1.7281826...</td>\n",
       "      <td>Because the term clearly noticeable has no spe...</td>\n",
       "      <td>Defines criteria for determining if a detected...</td>\n",
       "      <td>methodology_technical-assessment_test-products...</td>\n",
       "      <td>[28]</td>\n",
       "      <td>ae02281e5221ed329315c4c68c244bdb2f9ade29764b6c...</td>\n",
       "      <td>1.024306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensory analysis through the descriptive profi...</td>\n",
       "      <td>[0.3010092, -0.24398738, -3.4934468, -1.605134...</td>\n",
       "      <td>Sensory analysis through the descriptive profi...</td>\n",
       "      <td>Details the methodology for sensory analysis, ...</td>\n",
       "      <td>methodology_technical-assessment_test-products...</td>\n",
       "      <td>[20]</td>\n",
       "      <td>b4006357111f7d58b30ea71328ec9a1f790defd0ff60e3...</td>\n",
       "      <td>0.956337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  A rank rating test was used to assess the inte...   \n",
       "1  Because the term clearly noticeable has no spe...   \n",
       "2  Sensory analysis through the descriptive profi...   \n",
       "\n",
       "                                              vector  \\\n",
       "0  [-0.12656964, 0.45683643, -3.8943672, -1.77620...   \n",
       "1  [0.7338957, -0.12551239, -3.632481, -1.7281826...   \n",
       "2  [0.3010092, -0.24398738, -3.4934468, -1.605134...   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  A rank rating test was used to assess the inte...   \n",
       "1  Because the term clearly noticeable has no spe...   \n",
       "2  Sensory analysis through the descriptive profi...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Details the methodology for assessing whether ...   \n",
       "1  Defines criteria for determining if a detected...   \n",
       "2  Details the methodology for sensory analysis, ...   \n",
       "\n",
       "                                            document pages  \\\n",
       "0  methodology_technical-assessment_test-products...  [21]   \n",
       "1  methodology_technical-assessment_test-products...  [28]   \n",
       "2  methodology_technical-assessment_test-products...  [20]   \n",
       "\n",
       "                                                  id  _relevance_score  \n",
       "0  df5a96217dca6d7d6c5d976a18c9b98a7a79263efd8080...          1.140071  \n",
       "1  ae02281e5221ed329315c4c68c244bdb2f9ade29764b6c...          1.024306  \n",
       "2  b4006357111f7d58b30ea71328ec9a1f790defd0ff60e3...          0.956337  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How were different kinds of tobacco products assessed based on composite odour intensity\"\n",
    "results = table.search(prompt, query_type=\"hybrid\", vector_column_name=\"vector\", fts_columns=\"text\") \\\n",
    "            .rerank(reranker=reranker) \\\n",
    "            .limit(3) \\\n",
    "            .to_pandas()\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190f09d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A rank rating test was used to assess the intensity of the overall composite aroma for samples that were flagged as possibly containing a characterising flavour, during descriptive profiling. During rankrating, the composite odour of the sample is evaluated, rather than individual odour elements, reflecting how they are likely to be perceived by consumers. For example, a product may possess a composite aroma of mint chocolate comprising individual odour attributes of spearmint, peppermint, burnt sugar, vanilla and dark chocolate.\\nSensory panellists were instructed to rate the intensity of such a specified composite aroma in each flagged sample using a scale of 0 -10. For assessing if a tobacco product has a clearly noticeable flavour, the average intensity of the composite odour of the undiluted test sample is statistically compared with that of a reference product and with cut-off limits considered to represent a clearly noticeable odour intensity.\\n\\nDetails the methodology for assessing whether a tobacco product exhibits a distinct, characterizing flavor through rank-rating and statistical comparison with reference products.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25663f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantwise-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
