{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6bc954c",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c40da70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/projects/Quantwise/quantwise-venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "from transformers import AutoTokenizer\n",
    "import hashlib\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.rerankers import ColbertReranker\n",
    "import ollama\n",
    "\n",
    "\n",
    "embedding_model_name = \"nomic-ai/nomic-embed-text-v1.5\"\n",
    "MAX_TOKENS = 2000\n",
    "\n",
    "source = \"Stock_Market_Prediction_via_Multi-Source_Multiple_Instance_Learning.pdf\"  # document per local path or URL\n",
    "converter = DocumentConverter()\n",
    "doc = converter.convert(source).document\n",
    "\n",
    "tokenizer = HuggingFaceTokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(embedding_model_name),\n",
    "    max_tokens=MAX_TOKENS # Optional, uses the max token number of the HF tokenizer by default\n",
    ")\n",
    "\n",
    "\n",
    "chunker = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    merge_peers=True #Optional, defaults to true\n",
    ")\n",
    "chunks = list(chunker.chunk(dl_doc=doc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508b299",
   "metadata": {},
   "source": [
    "# Adding Metadata\n",
    "\n",
    "As well as semantic context with ollama (Anthropic style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df465975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context for chunk: Provides contextual information about the publication of the research paper, including its dates and DOI.\n",
      "Context for chunk: Introduces the core problem and proposed solution: a multi-source multiple instance model for predicting stock market movements by integrating events, sentiments, and quantitative data, with a focus on interpretable predictions.\n",
      "Context for chunk: Introduces the core problem: predicting stock market movements and highlights the challenge of integrating diverse data sources (quantitative data and qualitative descriptions like news and social media). It also establishes the key approach: utilizing a multi-source multiple instance learning (M-MI) model to fuse event representations and sentiments for improved predictions.\n",
      "Context for chunk: Summarizes the reliance on single data sources in existing event-driven stock prediction models and highlights the need for integrating multiple sources to overcome this limitation.\n",
      "Context for chunk: Highlights the limitations of existing MIL approaches in the context of stock prediction, specifically noting their reliance on single data sources and simple event features, and introduces the proposed M-MI model as a more robust alternative.\n",
      "Context for chunk: This chunk introduces the problem being addressed and outlines the framework to be presented, including the definition of key notations.\n",
      "Context for chunk: Provides a framework for predicting stock market movements by integrating heterogeneous data sources (news, sentiments, and quantitative data) and modeling the consistency among them.\n",
      "Context for chunk: Describes the framework for predicting stock market movements, integrating data from news, social media, and quantitative sources. It utilizes a Multiple Instance Learning (MIL) model with a novel event representation learning process and emphasizes the importance of source-specific weights to capture the consensus among different data sources.\n",
      "Context for chunk: Identifies the relative importance of different data sources in predicting market movements and outlines how to determine key information driving index changes.\n",
      "Context for chunk: Describes the process of extracting event representations from news articles and sentiments from social media posts, which are then used as inputs to the M-MI framework.\n",
      "Context for chunk: Details the process of extracting structured events from news text, outlining the use of HanLP for syntactic analysis, RBM training for event representation, and sentence2vec for final feature generation.\n",
      "Context for chunk: Explains the LDA-S method for sentiment extraction from social media posts, detailing its two-step process and the use of a sentiment word list to determine positive, negative, or neutral sentiment labels for each post.\n",
      "Context for chunk: Details the data collection process, specifically outlining the sources and types of data used for the studyâ€™s evaluation.\n",
      "Context for chunk: Provides a comparison of different baseline models for stock prediction, outlining the specific methods used and the criteria for evaluating their performance.\n",
      "Context for chunk: Summarizes the experimental setup and results, highlighting M-MI's superior performance compared to baselines and the importance of news events in predicting stock market movements.\n",
      "Context for chunk: Summarizes the core contribution: proposes a multi-source, multi-instance model for stock market prediction, emphasizing its novel event representation learning and the validation through two-year data.\n",
      "Context for chunk: Introduces the core methodology: a multi-source multiple instance learning model that integrates news events, sentiments, and quantitative data to predict stock market movement, emphasizing the novel event extraction and representation techniques.\n",
      "Context for chunk: Provides context on the authors and their affiliations, establishing the research team involved in the study.\n"
     ]
    }
   ],
   "source": [
    "chunks_with_metadata = []\n",
    "entire_doc = \"\"\n",
    "for chunk in chunks:\n",
    "    entire_doc += \" \" +chunk.text\n",
    "\n",
    "entire_doc = \"FULL DOCUMENT:\\n\" + entire_doc\n",
    "\n",
    "for chunk in chunks:    \n",
    "    \n",
    "    ollama_prompt = f\"CHUNK:\\n{chunk.text}\"\n",
    "    history =  [{'role': 'user', 'content': entire_doc}, {'role': 'user', 'content': ollama_prompt}]\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"chunker_full_doc\",\n",
    "        messages=history\n",
    "    )\n",
    "    context = response['message']['content']\n",
    "    print(f\"Context for chunk: {context}\")\n",
    "    text_to_embed = chunk.text + \"\\n\\n\" + context # We put the context AFTER the chunk to not mess up cosine similarity but still\n",
    "\n",
    "    pages = set(\n",
    "            prov.page_no\n",
    "            for doc_item in chunk.meta.doc_items\n",
    "            for prov in doc_item.prov\n",
    "        )\n",
    "    id = hashlib.sha256(chunk.text.encode()).hexdigest()\n",
    "    chunks_with_metadata.append({'text': text_to_embed, 'original_text':chunk.text, 'context':context, 'document':source, 'pages':list(pages), 'id': id})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9490cd2",
   "metadata": {},
   "source": [
    "# Creating Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7aa3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ColBERTRanker model colbert-ir/colbertv2.0 (this message can be suppressed by setting verbose=0)\n",
      "No device set\n",
      "Using device cuda\n",
      "No dtype set\n",
      "Using dtype torch.float32\n",
      "Loading model colbert-ir/colbertv2.0, this might take a while...\n",
      "Linear Dim set to: 128 for downcasting\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "registry = get_registry()\n",
    "hf = registry.get(\"huggingface\").create(name=embedding_model_name, trust_remote_code=True, device=\"cuda\" if torch.cuda.is_available() else \"cpu\") #TODO: Test if there's a point to running this on GPU. LanceDB seems indifferent to the device.\n",
    "\n",
    "\n",
    "# Define model\n",
    "class MyDocument(LanceModel):\n",
    "    text: str = hf.SourceField()\n",
    "    vector: Vector(hf.ndims()) = hf.VectorField()\n",
    "    original_text: str\n",
    "    context: str\n",
    "    document: str\n",
    "    pages: list[int]  # Any additional metadata\n",
    "    id: str  # Unique identifier for the chunk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"./db\")\n",
    "db.create_table(\"my_table\", schema=MyDocument, mode=\"overwrite\") # Uncommend this line when running this cell for the first time\n",
    "table = db.open_table(\"my_table\")\n",
    "table.add(chunks_with_metadata) # LanceDB doesn't check for duplicates by default\n",
    "table.create_scalar_index(\"id\", replace=True) # Index based on the chunk's id, used to manually prevent duplicates\n",
    "\n",
    "reranker = ColbertReranker()\n",
    "table.create_fts_index(\"text\", replace=True) # Used by the reranker as well as the hybrid search's BM25 index\n",
    "table.wait_for_index([\"text_idx\"])  # Wait for the indexing to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df7323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AddResult(version=31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.add(chunks_with_metadata) # LanceDB doesn't check for duplicates by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b04d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_with_metadata) # Should be the same number of chunks as in the original document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3357c7",
   "metadata": {},
   "source": [
    "# Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42b9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>original_text</th>\n",
       "      <th>context</th>\n",
       "      <th>document</th>\n",
       "      <th>pages</th>\n",
       "      <th>id</th>\n",
       "      <th>_relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We collected stock market-related information ...</td>\n",
       "      <td>[0.5996058, 1.1112232, -3.3586943, -0.36808917...</td>\n",
       "      <td>We collected stock market-related information ...</td>\n",
       "      <td>Details the data collection process, specifica...</td>\n",
       "      <td>Stock_Market_Prediction_via_Multi-Source_Multi...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>08aa975b95d5c9c782b71fcb335e2ab61751bb4c4f6bb1...</td>\n",
       "      <td>0.878606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We collected stock market-related information ...</td>\n",
       "      <td>[0.5996058, 1.1112232, -3.3586943, -0.36808917...</td>\n",
       "      <td>We collected stock market-related information ...</td>\n",
       "      <td>Details the data collection process, specifica...</td>\n",
       "      <td>Stock_Market_Prediction_via_Multi-Source_Multi...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>08aa975b95d5c9c782b71fcb335e2ab61751bb4c4f6bb1...</td>\n",
       "      <td>0.878606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stock markets play important roles in the econ...</td>\n",
       "      <td>[0.39195225, 1.1913257, -3.0367725, -0.3536288...</td>\n",
       "      <td>Stock markets play important roles in the econ...</td>\n",
       "      <td>Introduces the core problem: predicting stock ...</td>\n",
       "      <td>Stock_Market_Prediction_via_Multi-Source_Multi...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>7ad78330122f8822c806a60689a342ee4a4dc34abf7a77...</td>\n",
       "      <td>0.586552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  We collected stock market-related information ...   \n",
       "1  We collected stock market-related information ...   \n",
       "2  Stock markets play important roles in the econ...   \n",
       "\n",
       "                                              vector  \\\n",
       "0  [0.5996058, 1.1112232, -3.3586943, -0.36808917...   \n",
       "1  [0.5996058, 1.1112232, -3.3586943, -0.36808917...   \n",
       "2  [0.39195225, 1.1913257, -3.0367725, -0.3536288...   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  We collected stock market-related information ...   \n",
       "1  We collected stock market-related information ...   \n",
       "2  Stock markets play important roles in the econ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Details the data collection process, specifica...   \n",
       "1  Details the data collection process, specifica...   \n",
       "2  Introduces the core problem: predicting stock ...   \n",
       "\n",
       "                                            document   pages  \\\n",
       "0  Stock_Market_Prediction_via_Multi-Source_Multi...     [6]   \n",
       "1  Stock_Market_Prediction_via_Multi-Source_Multi...     [6]   \n",
       "2  Stock_Market_Prediction_via_Multi-Source_Multi...  [1, 2]   \n",
       "\n",
       "                                                  id  _relevance_score  \n",
       "0  08aa975b95d5c9c782b71fcb335e2ab61751bb4c4f6bb1...          0.878606  \n",
       "1  08aa975b95d5c9c782b71fcb335e2ab61751bb4c4f6bb1...          0.878606  \n",
       "2  7ad78330122f8822c806a60689a342ee4a4dc34abf7a77...          0.586552  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How was the stock-market related information collected?\"\n",
    "results = table.search(prompt, query_type=\"hybrid\", vector_column_name=\"vector\", fts_columns=\"text\") \\\n",
    "            .rerank(reranker=reranker) \\\n",
    "            .limit(3) \\\n",
    "            .to_pandas()\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf96b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10860 > 8192). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10860"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.count_tokens(entire_doc)  # Check how many tokens the prompt has, should be less than MAX_TOKENS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantwise-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
