[
    {
        "text": "This chunk introduces a machine learning approach using an artificial neural network (ANN) to predict transistor performance metrics affected by line edge roughness (LER) in FinFET devices. It details the dataset generation, evaluation method (using Earth Mover's Distance), and the architecture of the ANN, including a mixture of multivariate normal distributions, to address non-Gaussian distribution issues and improve prediction accuracy compared to traditional TCAD simulations.\n\nReceived May 11, 2021, accepted June 6, 2021, date of publication June 11, 2021, date of current version June 22, 2021.\nDigital Object Identifier 10.1 109/ACCESS.2021.3088461",
        "original_text": "Received May 11, 2021, accepted June 6, 2021, date of publication June 11, 2021, date of current version June 22, 2021.\nDigital Object Identifier 10.1 109/ACCESS.2021.3088461",
        "context": "This chunk introduces a machine learning approach using an artificial neural network (ANN) to predict transistor performance metrics affected by line edge roughness (LER) in FinFET devices. It details the dataset generation, evaluation method (using Earth Mover's Distance), and the architecture of the ANN, including a mixture of multivariate normal distributions, to address non-Gaussian distribution issues and improve prediction accuracy compared to traditional TCAD simulations.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            1
        ],
        "id": "13edd023ab6e240494f754af75c8884c586b1b4c9469f03c99a3a9a6939ba1b6"
    },
    {
        "text": "This chunk details the funding and institutional affiliation for the research, alongside a brief overview of the proposed machine learning approach to address line edge roughness in FinFET devices.\n\nDepartment of Electrical and Computer Engineering, Sungkyunkwan University, Suwon 16419, Republic of Korea\nCorresponding author: Changhwan Shin (cshin@skku.edu)\nThis work was supported in part by the National Research Foundation of Korea (NRF) grant funded by the Korea Government Ministry of Science and ICT (MSIT) under Grant 2020R1A2C1009063, and in part by the Future Semiconductor Device Technology Development Program under Grant 20003551 funded by the Ministry of Trade, Industry and Energy (MOTIE) and the Korea Semiconductor Research Consortium (KSRC).\n- ABSTRACT Line-edge-roughness (LER) is one of undesirable process-induced random variation sources. LER is mostly occurred in the process of photo-lithography and etching, and it provokes random variation in performance of transistors such as metal oxide semiconductor GLYPH<28>eld effect transistor (MOSFET), GLYPH<28>n-shaped GLYPH<28>eld effect transistor (FinFET), and gate-all-around GLYPH<28>eld effect transistor (GAAFET). LER was analyzed/characterized with technology computer-aided design (TCAD), but it is fundamentally very time consuming. To tackle this issue, machine learning (ML)-based method is proposed in this work. LER parameters (i.e., amplitude, and correlation length X, Y) are provided as inputs. Then, artiGLYPH<28>cial neural network (ANN) predicts 7-parameters [i.e., off-state leakage current (Ioff), saturation drain current (Idsat), linear drain current (Idlin), low drain current (Idlo), high drain current (Idhi), saturation threshold voltage (Vtsat), and linear threshold voltage (Vtlin)] which are usually used to evaluate the performance of FinFET. First, how datasets for training process of ANN were generated is explained. Next, the evaluation method for probabilistic problem is introduced. Finally, the architecture of ANN, training process and our new proposition is presented. It turned out that the prediction results (i.e., non-Gaussian distribution of device performance metrics) obtained from the ANN were very similar to that from TCAD in the respect of both qualitative and quantitative comparison.\nLine edge roughness, process-induced random variation, FinFET, machine learning,\n- INDEX TERMS artiGLYPH<28>cial neural network.",
        "original_text": "Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon 16419, Republic of Korea\nCorresponding author: Changhwan Shin (cshin@skku.edu)\nThis work was supported in part by the National Research Foundation of Korea (NRF) grant funded by the Korea Government Ministry of Science and ICT (MSIT) under Grant 2020R1A2C1009063, and in part by the Future Semiconductor Device Technology Development Program under Grant 20003551 funded by the Ministry of Trade, Industry and Energy (MOTIE) and the Korea Semiconductor Research Consortium (KSRC).\n- ABSTRACT Line-edge-roughness (LER) is one of undesirable process-induced random variation sources. LER is mostly occurred in the process of photo-lithography and etching, and it provokes random variation in performance of transistors such as metal oxide semiconductor GLYPH<28>eld effect transistor (MOSFET), GLYPH<28>n-shaped GLYPH<28>eld effect transistor (FinFET), and gate-all-around GLYPH<28>eld effect transistor (GAAFET). LER was analyzed/characterized with technology computer-aided design (TCAD), but it is fundamentally very time consuming. To tackle this issue, machine learning (ML)-based method is proposed in this work. LER parameters (i.e., amplitude, and correlation length X, Y) are provided as inputs. Then, artiGLYPH<28>cial neural network (ANN) predicts 7-parameters [i.e., off-state leakage current (Ioff), saturation drain current (Idsat), linear drain current (Idlin), low drain current (Idlo), high drain current (Idhi), saturation threshold voltage (Vtsat), and linear threshold voltage (Vtlin)] which are usually used to evaluate the performance of FinFET. First, how datasets for training process of ANN were generated is explained. Next, the evaluation method for probabilistic problem is introduced. Finally, the architecture of ANN, training process and our new proposition is presented. It turned out that the prediction results (i.e., non-Gaussian distribution of device performance metrics) obtained from the ANN were very similar to that from TCAD in the respect of both qualitative and quantitative comparison.\nLine edge roughness, process-induced random variation, FinFET, machine learning,\n- INDEX TERMS artiGLYPH<28>cial neural network.",
        "context": "This chunk details the funding and institutional affiliation for the research, alongside a brief overview of the proposed machine learning approach to address line edge roughness in FinFET devices.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            1
        ],
        "id": "67ee8ff59e145ba0f792599de7302dd62ece3933ee9becd56d809fc78b410611"
    },
    {
        "text": "The document introduces a machine learning approach to predict FinFET performance, specifically addressing the challenge of line edge roughness (LER) and its impact on transistor metrics. It details a novel ANN model designed to overcome limitations of previous Gaussian distribution assumptions and proposes a method for evaluating the model's accuracy using earth-mover's distance.\n\nOver the past a few decades, complementary metal oxide semiconductor (CMOS) technology has been evolved with advanced techniques such as stress engineering in 90 nm technology node [1], high-k/metal-gate (HK/MG) in 45 nm technology node [2], and three-dimensional advanced device structure in 22 nm technology node [3]. Those new techniques have enabled the physical dimension of metal oxide semiconductor GLYPH<28>eld effect transistor (MOSFET) to be successfully scaled down, resulting in the improved functions of integrated circuit (IC) per cost. However, there still exists secondary effects in aggressively scaled MOSFETs, and they should be overcome. Especially, one of those challenges, i.e., process-induced random variation, which randomly cause\nThe associate editor coordinating the review of this manuscript and approving it for publication was Kalyan Koley .\nvariation in transistor performance metrics such as threshold voltage, on-state drive current, and off-state leakage current, become signiGLYPH<28>cant as CMOS technology is evolved [4]. The primary causes of process-induced random variation can be classiGLYPH<28>ed as (i) line edge roughness (LER), (ii) random dopant GLYPH<29>uctuation (RDF), and (iii) work function variation (WFV) [5]. Among them, because LER can affect the other random variation sources (i.e., RDF and WFV) by inducing the deformation of device structure [6], it would degrade the device performance more severely. With the most radical shift in device architecture at 22 nm node, i.e., from planar bulk MOSFET to three-dimensional GLYPH<28>n-shaped GLYPH<28>eld effect transistor (FinFET), the process-induced random variation becomes much more severe [7]. As expected that a more 45 complicated device structure such as multiple bridge channel GLYPH<28>eld effect transistor (MBCFET), stacked nano-wire FET, complementary FET (CFET) would be adopted at 3 nm node\n[9], understanding and analyzing the impact of LER on device performance is essential for designing variation-robust silicon device.\nTo understand and quantify the impact of LER on device performance, TCAD has been used so far. TCAD simulation is, however, fundamentally very time-consuming. As another approach, compact model [10] has been used to overcome the time-inefGLYPH<28>ciency of using TCAD tools. However, the compact model for LER is still based on 2-D analysis, despite that 3-D analysis for LER is necessary [7]. As an alternative way to avoid those obstacles, we have focused on machine learning (ML)-based artiGLYPH<28>cial neural network (ANN). Machine Learning technology has already been in spotlight in various GLYPH<28>elds such as geology, and biology [11]GLYPH<21>[13]. Especially in semiconductor technologies, a number of studies have been reported in many branches such as fabrication [14], [15], optimization [16], and modeling [17]. Following this trend, we suggested a ML-based ANN model in our previous work [18]. However, it turned out that the ML-based ANN had limits, in that target performance metrics were assumed to follow multi-variate Gaussian distribution only. This assumption would cause some inevitable errors. Moreover, the ANN model has its own intrinsic limit in estimating the other performance metrics such as Idlo , and Idhi (which, in real, do not follow Gaussian distribution). Therefore, we would like to develop and propose an upgraded ANN model with enhanced accuracy (note that this new ANN model can overcome the limit mentioned above).\nIn this work, we show the way how FinFETs with LER are simulated as well as how those data are preprocessed for training process of ANN. Afterwards, the evaluation method used to assess the results of proposed work is introduced. Finally, it is shown how ANN was composed and built, including its geometrical structure, hyper parameters, and the process of grafting probability.",
        "original_text": "Over the past a few decades, complementary metal oxide semiconductor (CMOS) technology has been evolved with advanced techniques such as stress engineering in 90 nm technology node [1], high-k/metal-gate (HK/MG) in 45 nm technology node [2], and three-dimensional advanced device structure in 22 nm technology node [3]. Those new techniques have enabled the physical dimension of metal oxide semiconductor GLYPH<28>eld effect transistor (MOSFET) to be successfully scaled down, resulting in the improved functions of integrated circuit (IC) per cost. However, there still exists secondary effects in aggressively scaled MOSFETs, and they should be overcome. Especially, one of those challenges, i.e., process-induced random variation, which randomly cause\nThe associate editor coordinating the review of this manuscript and approving it for publication was Kalyan Koley .\nvariation in transistor performance metrics such as threshold voltage, on-state drive current, and off-state leakage current, become signiGLYPH<28>cant as CMOS technology is evolved [4]. The primary causes of process-induced random variation can be classiGLYPH<28>ed as (i) line edge roughness (LER), (ii) random dopant GLYPH<29>uctuation (RDF), and (iii) work function variation (WFV) [5]. Among them, because LER can affect the other random variation sources (i.e., RDF and WFV) by inducing the deformation of device structure [6], it would degrade the device performance more severely. With the most radical shift in device architecture at 22 nm node, i.e., from planar bulk MOSFET to three-dimensional GLYPH<28>n-shaped GLYPH<28>eld effect transistor (FinFET), the process-induced random variation becomes much more severe [7]. As expected that a more 45 complicated device structure such as multiple bridge channel GLYPH<28>eld effect transistor (MBCFET), stacked nano-wire FET, complementary FET (CFET) would be adopted at 3 nm node\n[9], understanding and analyzing the impact of LER on device performance is essential for designing variation-robust silicon device.\nTo understand and quantify the impact of LER on device performance, TCAD has been used so far. TCAD simulation is, however, fundamentally very time-consuming. As another approach, compact model [10] has been used to overcome the time-inefGLYPH<28>ciency of using TCAD tools. However, the compact model for LER is still based on 2-D analysis, despite that 3-D analysis for LER is necessary [7]. As an alternative way to avoid those obstacles, we have focused on machine learning (ML)-based artiGLYPH<28>cial neural network (ANN). Machine Learning technology has already been in spotlight in various GLYPH<28>elds such as geology, and biology [11]GLYPH<21>[13]. Especially in semiconductor technologies, a number of studies have been reported in many branches such as fabrication [14], [15], optimization [16], and modeling [17]. Following this trend, we suggested a ML-based ANN model in our previous work [18]. However, it turned out that the ML-based ANN had limits, in that target performance metrics were assumed to follow multi-variate Gaussian distribution only. This assumption would cause some inevitable errors. Moreover, the ANN model has its own intrinsic limit in estimating the other performance metrics such as Idlo , and Idhi (which, in real, do not follow Gaussian distribution). Therefore, we would like to develop and propose an upgraded ANN model with enhanced accuracy (note that this new ANN model can overcome the limit mentioned above).\nIn this work, we show the way how FinFETs with LER are simulated as well as how those data are preprocessed for training process of ANN. Afterwards, the evaluation method used to assess the results of proposed work is introduced. Finally, it is shown how ANN was composed and built, including its geometrical structure, hyper parameters, and the process of grafting probability.",
        "context": "The document introduces a machine learning approach to predict FinFET performance, specifically addressing the challenge of line edge roughness (LER) and its impact on transistor metrics. It details a novel ANN model designed to overcome limitations of previous Gaussian distribution assumptions and proposes a method for evaluating the model's accuracy using earth-mover's distance.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            1,
            2
        ],
        "id": "67cc20048dc953ca4401bea493596bb83b8a68e769d8f220e5c6b739a717009b"
    },
    {
        "text": "This chunk details the methodology for simulating FinFETs with line edge roughness (LER), utilizing a 3D quasi-atomistic model and parameters describing LER amplitude and correlation length. It outlines the use of MATLAB and TCAD Sentaurus for simulation, referencing previous work and specifying the parameters used (amplitude, correlation length X and Y) and their physical meaning.\n\nAsdone in the previous study [18], 3-D quasi atomistic model for line edge roughness was used [19]. Three parameters (i.e., 1 , 3 x, and 3 y) are used to describe and reconGLYPH<28>gure LER proGLYPH<28>le. The physical meaning of those parameters are as follows [see Fig 2]:\n- (i) Amplitude ( 1 ): it indicates the rms (root-meansquared) value of surface roughness.\n- (ii) Correlation length ( 3 ): it means how line edge is closely correlated with its neighboring edge. A larger 3 indicates a smoother line.\nFIGURE 1. A bird's-eye view of FinFET with a three-dimensional line-edge-roughness (LER) on its sidewall. LER parameters used in this example are as follows: 1 D 0 : 5 nm, 3 x D 20 nm, 3 y D 50 nm, GLYPH<11> D 1, and 2 D 0.\nFIGURE 2. Examples of roughness amplitude when (a) 3 D 10, and (b) 1 D 0.5.\nIn Eq. (1), as shown at the bottom of the page, 3 x and 3 y are the correlation length along x-direction and y-direction, respectively [see Fig. 1]. 2 indicates the relation between x-direction and y-direction.\nUsing parameters mentioned above and two-dimensional auto covariance function (ACVF), we have simulated FinFET with MATLAB and TCAD Sentaurus Structure Editor and Device [19], [20]. The detailed steps how to create a rough sidewall surface of FinFET are provided in [18], [19].\nNominal device parameters of FinFET is summarized in Table 1. Drift-diffusion simulation for the FinFETs with surface roughness are executed, using various models such as doping-dependent mobility model, thin-layer mobility model for carrier transport, the Shockley-Read-Hall (SRH) model for generation and recombination, high GLYPH<28>eld saturation model\n<!-- formula-not-decoded -->\nTABLE 1. Nominal device parameters of FinFET [8].\nTABLE 2. Performance metrics.\nfor velocity saturation, and a density-gradient quantization model for quantum-mechanical effects.",
        "original_text": "Asdone in the previous study [18], 3-D quasi atomistic model for line edge roughness was used [19]. Three parameters (i.e., 1 , 3 x, and 3 y) are used to describe and reconGLYPH<28>gure LER proGLYPH<28>le. The physical meaning of those parameters are as follows [see Fig 2]:\n- (i) Amplitude ( 1 ): it indicates the rms (root-meansquared) value of surface roughness.\n- (ii) Correlation length ( 3 ): it means how line edge is closely correlated with its neighboring edge. A larger 3 indicates a smoother line.\nFIGURE 1. A bird's-eye view of FinFET with a three-dimensional line-edge-roughness (LER) on its sidewall. LER parameters used in this example are as follows: 1 D 0 : 5 nm, 3 x D 20 nm, 3 y D 50 nm, GLYPH<11> D 1, and 2 D 0.\nFIGURE 2. Examples of roughness amplitude when (a) 3 D 10, and (b) 1 D 0.5.\nIn Eq. (1), as shown at the bottom of the page, 3 x and 3 y are the correlation length along x-direction and y-direction, respectively [see Fig. 1]. 2 indicates the relation between x-direction and y-direction.\nUsing parameters mentioned above and two-dimensional auto covariance function (ACVF), we have simulated FinFET with MATLAB and TCAD Sentaurus Structure Editor and Device [19], [20]. The detailed steps how to create a rough sidewall surface of FinFET are provided in [18], [19].\nNominal device parameters of FinFET is summarized in Table 1. Drift-diffusion simulation for the FinFETs with surface roughness are executed, using various models such as doping-dependent mobility model, thin-layer mobility model for carrier transport, the Shockley-Read-Hall (SRH) model for generation and recombination, high GLYPH<28>eld saturation model\n<!-- formula-not-decoded -->\nTABLE 1. Nominal device parameters of FinFET [8].\nTABLE 2. Performance metrics.\nfor velocity saturation, and a density-gradient quantization model for quantum-mechanical effects.",
        "context": "This chunk details the methodology for simulating FinFETs with line edge roughness (LER), utilizing a 3D quasi-atomistic model and parameters describing LER amplitude and correlation length. It outlines the use of MATLAB and TCAD Sentaurus for simulation, referencing previous work and specifying the parameters used (amplitude, correlation length X and Y) and their physical meaning.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            2,
            3
        ],
        "id": "ba77fab3e371f17c8d4404f048c643f41e908f572dac971dcfcd1e0016e09b90"
    },
    {
        "text": "This chunk details the creation and use of two datasets for training an artificial neural network (ANN) designed to predict FinFET performance metrics influenced by line edge roughness (LER). Specifically, it outlines the generation of 130 datasets (70% training, 30% validation) from 6,500 simulated FinFETs and 10 datasets from 2,500 FinFETs, alongside the selection of LER parameters within a defined voltage range and the extraction of performance metrics from simulated drain current versus gate voltage (Id-vs.-Vg) characteristics.\n\nTo train, validate, and test the ANN model that we have newly built up, two kinds of datasets were separately generated: (1) The GLYPH<28>rst kind of dataset has 130 datasets. Each dataset contains the performance metrics of 50 different FinFETs, so that total 6,500 FinFETs are used in 130 datasets. 70% of them are used as the training datasets, and the others are used as the validation datasets. (2) The second kind of dataset has 10 different datasets. Each dataset contains the performance metrics of 250 different FinFETs, so that total 2,500 FinFETs are used in 10 datasets.\nThe LER parameters are chosen in the range below V\nAmplitude ( 1 )\nV 0 : 1 nm GLYPH<24> 0 : 8 nm\nCorrelation length X( 3 x) V 10 nm GLYPH<24> 100 nm\nCorrelation length Y( 3 y) V 20 nm GLYPH<24> 200 nm\nThe reference parameter set ( 1 D 0.5 nm, 3 x D 20 nm, 3 y D 50 nm) is obtained, based on experimental results [21]GLYPH<21>[24]. Then, the range is selected on the basis of the reference parameter set. Note that the performance metrics of transistor were extracted from simulated drain current versus gate voltage (Id-vs.-Vg) characteristic. The details on the device performance metrics are summarized in Table 2. These metrics are extracted using the Sentaurus TCAD inspect [20].",
        "original_text": "To train, validate, and test the ANN model that we have newly built up, two kinds of datasets were separately generated: (1) The GLYPH<28>rst kind of dataset has 130 datasets. Each dataset contains the performance metrics of 50 different FinFETs, so that total 6,500 FinFETs are used in 130 datasets. 70% of them are used as the training datasets, and the others are used as the validation datasets. (2) The second kind of dataset has 10 different datasets. Each dataset contains the performance metrics of 250 different FinFETs, so that total 2,500 FinFETs are used in 10 datasets.\nThe LER parameters are chosen in the range below V\nAmplitude ( 1 )\nV 0 : 1 nm GLYPH<24> 0 : 8 nm\nCorrelation length X( 3 x) V 10 nm GLYPH<24> 100 nm\nCorrelation length Y( 3 y) V 20 nm GLYPH<24> 200 nm\nThe reference parameter set ( 1 D 0.5 nm, 3 x D 20 nm, 3 y D 50 nm) is obtained, based on experimental results [21]GLYPH<21>[24]. Then, the range is selected on the basis of the reference parameter set. Note that the performance metrics of transistor were extracted from simulated drain current versus gate voltage (Id-vs.-Vg) characteristic. The details on the device performance metrics are summarized in Table 2. These metrics are extracted using the Sentaurus TCAD inspect [20].",
        "context": "This chunk details the creation and use of two datasets for training an artificial neural network (ANN) designed to predict FinFET performance metrics influenced by line edge roughness (LER). Specifically, it outlines the generation of 130 datasets (70% training, 30% validation) from 6,500 simulated FinFETs and 10 datasets from 2,500 FinFETs, alongside the selection of LER parameters within a defined voltage range and the extraction of performance metrics from simulated drain current versus gate voltage (Id-vs.-Vg) characteristics.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            3
        ],
        "id": "ebd31e6ca79e50e00bd8ac62e6e03f71b4d485ce9b7a2d16c9c21eb800778c85"
    },
    {
        "text": "Quantifies the difference between TCAD dataset and ANN predictions using the Earth-mover's distance (EMD) metric, outlining the steps for calculating the EMD score and its significance in comparing probability distributions.\n\nTo quantitatively verify the distribution of values obtained from the new ANN model, we used earth-mover's distance (EMD) score (or be referred to as Wasserstein metric\nFIGURE 3. Conceptual diagram for showing the mixture of multivariate normal distributions.\nin mathematics). The EMD score is used to measure how two probability distributions are different from each other [25]. The deGLYPH<28>nition of the score is ''The minimal amount of work needed to transform one distribution to another distribution''. The EMD score can be calculated following the steps below:\nStep I: Calculate the difference of cumulative distribution function (CDF) of TCAD datasets and ANN prediction datasets.\nStep II: Normalize the calculated value in Step I.\nIn this work, we used Gaussian kernel density estimation (KDE) to estimate CDF of datasets. The EMD score is ''0'' when two distributions are exactly identical.",
        "original_text": "To quantitatively verify the distribution of values obtained from the new ANN model, we used earth-mover's distance (EMD) score (or be referred to as Wasserstein metric\nFIGURE 3. Conceptual diagram for showing the mixture of multivariate normal distributions.\nin mathematics). The EMD score is used to measure how two probability distributions are different from each other [25]. The deGLYPH<28>nition of the score is ''The minimal amount of work needed to transform one distribution to another distribution''. The EMD score can be calculated following the steps below:\nStep I: Calculate the difference of cumulative distribution function (CDF) of TCAD datasets and ANN prediction datasets.\nStep II: Normalize the calculated value in Step I.\nIn this work, we used Gaussian kernel density estimation (KDE) to estimate CDF of datasets. The EMD score is ''0'' when two distributions are exactly identical.",
        "context": "Quantifies the difference between TCAD dataset and ANN predictions using the Earth-mover's distance (EMD) metric, outlining the steps for calculating the EMD score and its significance in comparing probability distributions.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            3
        ],
        "id": "061a8d07cee4b5796e315775572201e0a08ef619d49126f342a9283bcfbd91ea"
    },
    {
        "text": "Introduces the use of a mixture of multivariate normal distributions (MVNs) to account for non-Gaussian behavior in transistor performance metrics, specifically driven by non-ideal effects like short-channel effects.\n\nDifferent from the previous study [10], the mixture of multivariate normal distributions (MVN) is used in this work. By using the mixture of MVNs, we can respond to many other unknown distribution shapes. It is trivial that performance metrics of transistor approximately follow Gaussian distribution [26]GLYPH<21>[28]. However, triggered by many non-ideal effects in transistors (i.e., short-channel effects [29]), there are some skewness, kurtosis, and/or non-linear correlation in-between the performance metrics. Moreover, distribution shapes are also quite different, for each LER parameter. For those reasons, the mixture of MVNs was used to deal with the non-ideal cases. A conceptual diagram for the mixture of MVNs is shown in Fig. 3.\nTo determine the number of components (i.e., MVN distributions) used in generating the mixture of MVNs, an optimization was GLYPH<28>rst done. V alidation datasets were used in the training process, to GLYPH<28>nd the best working model. In Fig. 4, it can be noted that the validation loss was minimized with the number of components of 11 at 7,800 epochs. This means that the ANN model with 11 MVNs works best to describe the distribution of performance metrics. The optimized ANN with the mixture of MVNs has 3 neurons for the input layer, 81 neurons for the GLYPH<28>rst hidden layer, 162 neurons for the second hidden layer, 324 for the third hidden layer, and 324 neurons for the output layer. This output neurons are\nFIGURE 4. Validation loss vs. the number of epochs, when the number of distribution used to mixture is varied from 9 to 13.\nFIGURE 5. The flow chart how to build/train/test the ANN model.\nconnected to probabilistic layer with the mixture of multivariate normal distribution, for the generation of power density function (PDF) of output variables (performance metrics).",
        "original_text": "Different from the previous study [10], the mixture of multivariate normal distributions (MVN) is used in this work. By using the mixture of MVNs, we can respond to many other unknown distribution shapes. It is trivial that performance metrics of transistor approximately follow Gaussian distribution [26]GLYPH<21>[28]. However, triggered by many non-ideal effects in transistors (i.e., short-channel effects [29]), there are some skewness, kurtosis, and/or non-linear correlation in-between the performance metrics. Moreover, distribution shapes are also quite different, for each LER parameter. For those reasons, the mixture of MVNs was used to deal with the non-ideal cases. A conceptual diagram for the mixture of MVNs is shown in Fig. 3.\nTo determine the number of components (i.e., MVN distributions) used in generating the mixture of MVNs, an optimization was GLYPH<28>rst done. V alidation datasets were used in the training process, to GLYPH<28>nd the best working model. In Fig. 4, it can be noted that the validation loss was minimized with the number of components of 11 at 7,800 epochs. This means that the ANN model with 11 MVNs works best to describe the distribution of performance metrics. The optimized ANN with the mixture of MVNs has 3 neurons for the input layer, 81 neurons for the GLYPH<28>rst hidden layer, 162 neurons for the second hidden layer, 324 for the third hidden layer, and 324 neurons for the output layer. This output neurons are\nFIGURE 4. Validation loss vs. the number of epochs, when the number of distribution used to mixture is varied from 9 to 13.\nFIGURE 5. The flow chart how to build/train/test the ANN model.\nconnected to probabilistic layer with the mixture of multivariate normal distribution, for the generation of power density function (PDF) of output variables (performance metrics).",
        "context": "Introduces the use of a mixture of multivariate normal distributions (MVNs) to account for non-Gaussian behavior in transistor performance metrics, specifically driven by non-ideal effects like short-channel effects.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            3,
            4
        ],
        "id": "162dab2f62129f1b2441783099b32df98f5b8926a1457eb43ad2f723462cd3f3"
    },
    {
        "text": "Introduces a simpler ANN designed solely to estimate mean and standard deviation, reducing training time and enabling a focus on modeling the probability distribution shape.\n\nUnlike the proposed ANN in the previous section, another simple ANN was built only for estimating mean and standard deviation. With this simple ANN, the performance metrics were standardized in the training process of ANN with the mixture of MVNs [see Fig. 5]. By using additional simple ANN, we can limit the role of ANN with the mixture of MVNs, to just estimate the shape of probability distribution. Thus, the time spent to train the ANN model can be largely reduced (see Table 3). The simple ANN has 3 neurons for the input layer, 3 neurons for the GLYPH<28>rst hidden layer, 7 neurons for the second hidden layer, 14 neurons for the third hidden layer, and 14 neurons for the output layer. To compare this work against the non-separated ANN (note that the ANN model\nTABLE 3. Time spent to train ANN model.\ncan predict the mean, standard deviation, and the shape of distribution, at once), the same work mentioned in Part A was repeated to GLYPH<28>nd the optimized ANN (i.e., the number of MVNs, training epochs, etc.).",
        "original_text": "Unlike the proposed ANN in the previous section, another simple ANN was built only for estimating mean and standard deviation. With this simple ANN, the performance metrics were standardized in the training process of ANN with the mixture of MVNs [see Fig. 5]. By using additional simple ANN, we can limit the role of ANN with the mixture of MVNs, to just estimate the shape of probability distribution. Thus, the time spent to train the ANN model can be largely reduced (see Table 3). The simple ANN has 3 neurons for the input layer, 3 neurons for the GLYPH<28>rst hidden layer, 7 neurons for the second hidden layer, 14 neurons for the third hidden layer, and 14 neurons for the output layer. To compare this work against the non-separated ANN (note that the ANN model\nTABLE 3. Time spent to train ANN model.\ncan predict the mean, standard deviation, and the shape of distribution, at once), the same work mentioned in Part A was repeated to GLYPH<28>nd the optimized ANN (i.e., the number of MVNs, training epochs, etc.).",
        "context": "Introduces a simpler ANN designed solely to estimate mean and standard deviation, reducing training time and enabling a focus on modeling the probability distribution shape.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            4
        ],
        "id": "0683b94871fa28ca24ee920927d7e7580363e697b18b1ef0198bf02ea2bd7c9c"
    },
    {
        "text": "Details the ANN training process, specifically outlining the use of Negative log likelihood as a loss function and Maximum Likelihood Estimation.\n\nThe weight matrices and bias vectors of ANN model are updated for the given/speciGLYPH<28>ed number of iterations. These matrices and vectors determine the output of ANN model. The probabilistic layer attached to output neurons returns the PDF of variables while training process. Thus, conventional mean-squared error cannot be used as loss function. Instead, ''Negative log likelihood'' (Negloglik) was used as a loss function [see Eq. (2)]. The training process is executed to minimize this loss function. That is, training ANN becomes the process of Maximum Likelihood Estimation (MLE) [30].\n<!-- formula-not-decoded -->\nIn Eq. (2), P(x) and Q(x) denotes the PDF of observation and hypothesis, respectively.\nUsing Adam Optimizer [31], the training process was executed for 14,880 epochs (84 sec) for mean and standard deviation of ANN model and 7,800 epochs (101 sec) for the mixture of MVNs ANN model. Both models are trained with the learning rate of 10 GLYPH<0> 4 , and then optimized to prevent the occurrence of over-GLYPH<28>tting by using validation datasets. ReLU was used as the activation function for both models. Note that the ANN model was built using the TensorGLYPH<29>ow 2.0 and TensorGLYPH<29>ow-probability python library [32], [33].",
        "original_text": "The weight matrices and bias vectors of ANN model are updated for the given/speciGLYPH<28>ed number of iterations. These matrices and vectors determine the output of ANN model. The probabilistic layer attached to output neurons returns the PDF of variables while training process. Thus, conventional mean-squared error cannot be used as loss function. Instead, ''Negative log likelihood'' (Negloglik) was used as a loss function [see Eq. (2)]. The training process is executed to minimize this loss function. That is, training ANN becomes the process of Maximum Likelihood Estimation (MLE) [30].\n<!-- formula-not-decoded -->\nIn Eq. (2), P(x) and Q(x) denotes the PDF of observation and hypothesis, respectively.\nUsing Adam Optimizer [31], the training process was executed for 14,880 epochs (84 sec) for mean and standard deviation of ANN model and 7,800 epochs (101 sec) for the mixture of MVNs ANN model. Both models are trained with the learning rate of 10 GLYPH<0> 4 , and then optimized to prevent the occurrence of over-GLYPH<28>tting by using validation datasets. ReLU was used as the activation function for both models. Note that the ANN model was built using the TensorGLYPH<29>ow 2.0 and TensorGLYPH<29>ow-probability python library [32], [33].",
        "context": "Details the ANN training process, specifically outlining the use of Negative log likelihood as a loss function and Maximum Likelihood Estimation.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            4
        ],
        "id": "cee1f43f262f5b67a8a64cb41b5a475b435d0a7ce1cd04b532a8618ab6a6131a"
    },
    {
        "text": "Provides a comparison of prediction accuracy between the proposed work and a non-separated ANN model, demonstrating improved performance in predicting skewness, kurtosis, and non-linear correlation.\n\nBased on the PDF determined by the mixture of MVNs, the standardized prediction data was randomly extracted. Then, these standardized values are recovered with the predicted mean and standard deviation to the original scale (see Fig. 5).\nFig. 6 shows the comparison between the previous work, non-separated ANN, and this work, for a given LER of 1 D 0.505 nm, 3 x D 48.62 nm, 3 y D 67.99 nm. As shown in Fig. 5(a, b), previous work with plain MVN cannot predict metrics with non-linear correlation, skewness and kurtosis. On the other hand, ANN with mixture of MVN [see Fig. 6(c-f)] successfully predicts skewness, kurtosis, and non-linear correlation, which is distinctly different from plain MVN. EMD score also proves that prediction accuracy is highly improved (0.0170 vs 0.00928). As shown in Fig. 6(c-f), there is no signiGLYPH<28>cant performance degradation\nFIGURE 6. Histograms of (a, b) previous work, (c, d) non-separated model, and (e, f) this work. EMD score of (b), (d), and (f) is 0.0170, 0.00785, and 0.00928, respectively.\nTABLE 4. Comparison of EMD score between this work and non-separated ANN model.\nFIGURE 7. Pair plot of performance metrics for 1 D 0.505 nm, 3 x D 48.62 nm, 3 y D 67.99 nm.\nbetween non-separated ANN model and this work, in spite of huge time saving (1412 sec to 185 sec) [see Table 3].\nThe pair plots for 1 D 0.505 nm, 3 x D 48.62 nm, 3 y D 67.99 nm, and 1 D 0.690 nm, 3 x D 85.09 nm,\n3 y D 80.98 nm are shown in [See Fig. 7 and Fig. 8]. We can notify that distribution for each parameter (a diagonal line) and correlation between parameters (the rest except for a diagonal line) are well predicted.\nVtlin\nFIGURE 8. Pair plot of performance metrics 1 D 0.690 nm, 3 x D 85.09 nm, 3 y D 80.98 nm.\nTable 4 shows the EMD score comparison of performance metric. In the respect of quantitative analysis, it is shown that this work shows quite similar performance with non-separated ANN, when the amplitude of LER proGLYPH<28>le is around 0.5 or 0.6. However, it shows enhanced performance in a wider range than the non-separated ANN model. This work not only predicts the mean and standard deviation at a high level with the additional simple ANN, but also\nshows higher consistency for speciGLYPH<28>c points such as the tail of distribution by using the mixture of MVNs.",
        "original_text": "Based on the PDF determined by the mixture of MVNs, the standardized prediction data was randomly extracted. Then, these standardized values are recovered with the predicted mean and standard deviation to the original scale (see Fig. 5).\nFig. 6 shows the comparison between the previous work, non-separated ANN, and this work, for a given LER of 1 D 0.505 nm, 3 x D 48.62 nm, 3 y D 67.99 nm. As shown in Fig. 5(a, b), previous work with plain MVN cannot predict metrics with non-linear correlation, skewness and kurtosis. On the other hand, ANN with mixture of MVN [see Fig. 6(c-f)] successfully predicts skewness, kurtosis, and non-linear correlation, which is distinctly different from plain MVN. EMD score also proves that prediction accuracy is highly improved (0.0170 vs 0.00928). As shown in Fig. 6(c-f), there is no signiGLYPH<28>cant performance degradation\nFIGURE 6. Histograms of (a, b) previous work, (c, d) non-separated model, and (e, f) this work. EMD score of (b), (d), and (f) is 0.0170, 0.00785, and 0.00928, respectively.\nTABLE 4. Comparison of EMD score between this work and non-separated ANN model.\nFIGURE 7. Pair plot of performance metrics for 1 D 0.505 nm, 3 x D 48.62 nm, 3 y D 67.99 nm.\nbetween non-separated ANN model and this work, in spite of huge time saving (1412 sec to 185 sec) [see Table 3].\nThe pair plots for 1 D 0.505 nm, 3 x D 48.62 nm, 3 y D 67.99 nm, and 1 D 0.690 nm, 3 x D 85.09 nm,\n3 y D 80.98 nm are shown in [See Fig. 7 and Fig. 8]. We can notify that distribution for each parameter (a diagonal line) and correlation between parameters (the rest except for a diagonal line) are well predicted.\nVtlin\nFIGURE 8. Pair plot of performance metrics 1 D 0.690 nm, 3 x D 85.09 nm, 3 y D 80.98 nm.\nTable 4 shows the EMD score comparison of performance metric. In the respect of quantitative analysis, it is shown that this work shows quite similar performance with non-separated ANN, when the amplitude of LER proGLYPH<28>le is around 0.5 or 0.6. However, it shows enhanced performance in a wider range than the non-separated ANN model. This work not only predicts the mean and standard deviation at a high level with the additional simple ANN, but also\nshows higher consistency for speciGLYPH<28>c points such as the tail of distribution by using the mixture of MVNs.",
        "context": "Provides a comparison of prediction accuracy between the proposed work and a non-separated ANN model, demonstrating improved performance in predicting skewness, kurtosis, and non-linear correlation.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            4,
            5,
            6,
            7,
            8
        ],
        "id": "d5f0ec052fdd40c9f5c8a0e7e5ed2fa80518ec3d41592c76c7d3c079e744d28f"
    },
    {
        "text": "Shortened the simulation time by six times compared to a previous ML-based model, successfully predicting non-Gaussian device performance metrics not achievable by the prior model, and expanded the prediction target to include more transistor parameters.\n\nWe have proposed newly developed ANN models with enhanced accuracy. A ML-based model [14] was GLYPH<28>rst suggested to estimate LER-induced random variation, and its simulation time was shorter than using compact models. Herein, compared against the previous ML-based model [14], the newly proposed ANN models have shortened the simulation time by GLYPH<24> 6 times (from 1,191 seconds to 185 seconds). Especially, non-Gaussian features of device performance metrics' distribution (i.e., skewness, kurtosis, and non-linear correlation) are successfully predicted while the previous ML model only did with a shape of Gaussian distribution and linear correlation. Thus, the accuracy of the ANN model is signiGLYPH<28>cantly improved in the respect of both quantitative and qualitative comparisons. Especially, we extend the prediction target from 4 parameters such as Ioff, Idsat, Vtsat, and SS (Subthreshold Swing) to 7 parameters such as Ioff, Idsat, Idlin, Idlo , Idhi , Vtsat, and Vtlin. This enables simulating electrical behavior of transistor as well as DC behavior of digital circuit blocks such as SRAM bit cell [34]. This work can pave a new road to analyzing the impact of LER, and thereby, to timely design the process integration for integrated circuits.",
        "original_text": "We have proposed newly developed ANN models with enhanced accuracy. A ML-based model [14] was GLYPH<28>rst suggested to estimate LER-induced random variation, and its simulation time was shorter than using compact models. Herein, compared against the previous ML-based model [14], the newly proposed ANN models have shortened the simulation time by GLYPH<24> 6 times (from 1,191 seconds to 185 seconds). Especially, non-Gaussian features of device performance metrics' distribution (i.e., skewness, kurtosis, and non-linear correlation) are successfully predicted while the previous ML model only did with a shape of Gaussian distribution and linear correlation. Thus, the accuracy of the ANN model is signiGLYPH<28>cantly improved in the respect of both quantitative and qualitative comparisons. Especially, we extend the prediction target from 4 parameters such as Ioff, Idsat, Vtsat, and SS (Subthreshold Swing) to 7 parameters such as Ioff, Idsat, Idlin, Idlo , Idhi , Vtsat, and Vtlin. This enables simulating electrical behavior of transistor as well as DC behavior of digital circuit blocks such as SRAM bit cell [34]. This work can pave a new road to analyzing the impact of LER, and thereby, to timely design the process integration for integrated circuits.",
        "context": "Shortened the simulation time by six times compared to a previous ML-based model, successfully predicting non-Gaussian device performance metrics not achievable by the prior model, and expanded the prediction target to include more transistor parameters.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            8
        ],
        "id": "e5641ee5926b64216a040b28fefa9fc5eab8f7053062fe751b20c411f0aee4cf"
    },
    {
        "text": "Provides support and funding for the research.\n\nThe EDA Tool was supported by the IC Design Education Center (IDEC), Republic of Korea.",
        "original_text": "The EDA Tool was supported by the IC Design Education Center (IDEC), Republic of Korea.",
        "context": "Provides support and funding for the research.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            8
        ],
        "id": "8e527ea97e0d87289b7b8525dfb4f6fc1bbb0a48744f093c80e090402abf1f52"
    },
    {
        "text": "Provides supporting evidence for the argument on economic inequality; Introduces the central thesis about climate policy reform; Transitions from background information to proposed methodology; Introduces the simple ANN model and its purpose.\n\n- [1] K. Mistry, M. Armstrong, C. Auth, S. Cea, T. Coan, T. Ghani, T. Hoffmann, A. Murthy, J. Sandford, R. Shaheed, K. Zawadzki, K. Zhang, S. Thompson, and M. Bohr, ''Delaying forever: Uniaxial strained silicon transistors in a 90 nm CMOS technology,'' in Proc. Dig. Tech. Papers. Symp. VLSI Technol. , 2004, pp. 50GLYPH<21>51.\n- [2] C. Auth et al. , ''45 nm high-k C metal gate strain-enhanced transistors,'' in Proc. Symp. VLSI Technol. , Jun. 2008, pp. 128GLYPH<21>129.\n- [3] C. Auth et al. , ''A 22 nm high performance and low-power CMOS technology featuring fully-depleted tri-gate transistors, self-aligned contacts and high density MIM capacitors,'' in Proc. Symp. VLSI Technol. (VLSIT) , Jun. 2012, pp. 131GLYPH<21>132.\n- [4] K. Agarwal and S. Nassif, ''The impact of random device variation on SRAMcell stability in sub-90-nm CMOS technologies,'' IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 16, no. 1, pp. 86GLYPH<21>97, Jan. 2008.\n- [5] S. Markov, A. S. M. Zain, B. Cheng, and A. Asenov, ''Statistical variability in scaled generations of n-channel UTB-FD-SOI MOSFETs under the inGLYPH<29>uence of RDF, LER, OTF and MGG,'' in Proc. IEEE Int. SOI Conf. (SOI) , Oct. 2012, pp. 1GLYPH<21>2.\n- [6] G. Leung and C. O. Chui, ''Interactions between line edge roughness and random dopant GLYPH<29>uctuation in nonplanar GLYPH<28>eld-effect transistor variability,'' IEEE Trans. Electron Devices , vol. 60, no. 10, pp. 3277GLYPH<21>3284, Oct. 2013.\n- [7] W.-T. Huang and Y. Li, ''The impact of GLYPH<28>n/sidewall/gate line edge roughness on trapezoidal bulk FinFET devices,'' in Proc. Int. Conf. Simul. Semiconductor Processes Devices (SISPAD) , Sep. 2014, pp. 281GLYPH<21>284.\n- [8] M. Badaroglu. (2018). International Roadmap for Device and Systems (IRDS) . [Online]. Available: \n- [9] G. Bae et al. , ''3 nm GAA technology featuring multi-bridge-channel FET for low power and high performance applications,'' in IEDM Tech. Dig. , Dec. 2018, pp. 28.7.1GLYPH<21>28.7.4.\n- [10] X. Jiang, X. Wang, R. Wang, B. Cheng, A. Asenov, and R. Huang, ''Predictive compact modeling of random variations in FinFET technology for 16/14 nm node and beyond,'' in IEDM Tech. Dig. , Dec. 2015, pp. 28.3.1GLYPH<21>28.3.4.\n- [11] M. H. A. Banna, K. A. Taher, M. S. Kaiser, M. Mahmud, M. S. Rahman, A. S. M. S. Hosen, and G. H. Cho, ''Application of artiGLYPH<28>cial intelligence in predicting earthquakes: State-of-the-art and future challenges,'' IEEE Access , vol. 8, pp. 192880GLYPH<21>192923, 2020.\n- [12] M. B. T. Noor, N. Z. Zenia, M. S. Kaiser, S. A. Mamun, and M. Mahmud, ''Application of deep learning in detecting neurological disorders from magnetic resonance images: A survey on the detection of Alzheimer's disease, Parkinson's disease and schizophrenia,'' Brain Informat. , vol. 7, no. 1, pp. 1GLYPH<21>21, Dec. 2020.\n- [13] A. Whata and C. Chimedza, ''Deep learning for SARS COV-2 genome sequences,'' IEEE Access , vol. 9, pp. 59597GLYPH<21>59611, 2021.\n- [14] H.-C. Choi, H. Yun, J.-S. Yoon, and R.-H. Baek, ''Neural approach for modeling and optimizing Si-MOSFET manufacturing,'' IEEE Access , vol. 8, pp. 159351GLYPH<21>159370, 2020.\n- [15] D. Jiang, W. Lin, and N. Raghavan, ''A Gaussian mixture model clustering ensemble regressor for semiconductor manufacturing GLYPH<28>nal test yield prediction,'' IEEE Access , vol. 9, pp. 22253GLYPH<21>22263, 2021.\n- [16] J.-S. Yoon, S. Lee, H. Yun, and R.-H. Baek, ''Digital/analog performance optimization of vertical nanowire FETs using machine learning,'' IEEE Access , vol. 9, pp. 29071GLYPH<21>29077, 2021.\n- [17] K. Ko, J. K. Lee, and H. Shin, ''Variability-aware machine learning strategy for 3-D NAND GLYPH<29>ash memories,'' IEEE Trans. Electron Devices , vol. 67, no. 4, pp. 1575GLYPH<21>1580, Apr. 2020.\n- [18] J. Lim and C. Shin, ''Machine learning (ML)-based model to characterize the line edge roughness (LER)-induced random variation in FinFET,'' IEEE Access , vol. 8, pp. 158237GLYPH<21>158242, 2020.\n- [19] S. Oh and C. Shin, ''3-D quasi-atomistic model for line edge roughness in nonplanar MOSFETs,'' IEEE Trans. Electron Devices , vol. 63, no. 12, pp. 4617GLYPH<21>4623, Dec. 2016.\n- [20] TCAD Sentaurus? User Guide Version P-2019.03 , Synopsys, Inc., Mountain View, CA, USA, 2019.\n- [21] C. Shin, Variation-Aware Advanced CMOS Devices and SRAM , vol. 56. Dordrecht, The Netherlands: Springer, 2016.\n- [22] E. Dornel, T. Ernst, J. C. Barb, J. M. Hartmann, V. Delaye, F. Aussenac, C. Vizioz, S. Borel, V . MafGLYPH<28>ni-Alvaro, C. Isheden, and J. Foucher, ''Hydrogen annealing of arrays of planar and vertically stacked Si nanowires,'' Appl. Phys. Lett. , vol. 91, no. 23, Dec. 2007, Art. no. 233502.\n- [23] T. Tezuka, N. Hirashita, Y. Moriyama, N. Sugiyama, K. Usuda, E. Toyoda, K. Murayama, and S.-I. Takagi, ''110-facets formation by hydrogen thermal etching on sidewalls of Si and strained-Si GLYPH<28>n structures,'' Appl. Phys. Lett. , vol. 92, no. 19, May 2008, Art. no. 191903.\n- [24] Y. Ma, H. J. Levinson, and T. Wallow, ''Line edge roughness impact on critical dimension variation,'' Proc. SPIE , vol. 6518, Apr. 2007, Art. no. 651824.\n- [25] Y. Rubner, C. Tomasi, and L. J. Guibas, ''A metric for distributions with applications to image databases,'' in Proc. 6th Int. Conf. Comput. Vis. , Jan. 1998, pp. 59GLYPH<21>66.",
        "original_text": "- [1] K. Mistry, M. Armstrong, C. Auth, S. Cea, T. Coan, T. Ghani, T. Hoffmann, A. Murthy, J. Sandford, R. Shaheed, K. Zawadzki, K. Zhang, S. Thompson, and M. Bohr, ''Delaying forever: Uniaxial strained silicon transistors in a 90 nm CMOS technology,'' in Proc. Dig. Tech. Papers. Symp. VLSI Technol. , 2004, pp. 50GLYPH<21>51.\n- [2] C. Auth et al. , ''45 nm high-k C metal gate strain-enhanced transistors,'' in Proc. Symp. VLSI Technol. , Jun. 2008, pp. 128GLYPH<21>129.\n- [3] C. Auth et al. , ''A 22 nm high performance and low-power CMOS technology featuring fully-depleted tri-gate transistors, self-aligned contacts and high density MIM capacitors,'' in Proc. Symp. VLSI Technol. (VLSIT) , Jun. 2012, pp. 131GLYPH<21>132.\n- [4] K. Agarwal and S. Nassif, ''The impact of random device variation on SRAMcell stability in sub-90-nm CMOS technologies,'' IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 16, no. 1, pp. 86GLYPH<21>97, Jan. 2008.\n- [5] S. Markov, A. S. M. Zain, B. Cheng, and A. Asenov, ''Statistical variability in scaled generations of n-channel UTB-FD-SOI MOSFETs under the inGLYPH<29>uence of RDF, LER, OTF and MGG,'' in Proc. IEEE Int. SOI Conf. (SOI) , Oct. 2012, pp. 1GLYPH<21>2.\n- [6] G. Leung and C. O. Chui, ''Interactions between line edge roughness and random dopant GLYPH<29>uctuation in nonplanar GLYPH<28>eld-effect transistor variability,'' IEEE Trans. Electron Devices , vol. 60, no. 10, pp. 3277GLYPH<21>3284, Oct. 2013.\n- [7] W.-T. Huang and Y. Li, ''The impact of GLYPH<28>n/sidewall/gate line edge roughness on trapezoidal bulk FinFET devices,'' in Proc. Int. Conf. Simul. Semiconductor Processes Devices (SISPAD) , Sep. 2014, pp. 281GLYPH<21>284.\n- [8] M. Badaroglu. (2018). International Roadmap for Device and Systems (IRDS) . [Online]. Available: \n- [9] G. Bae et al. , ''3 nm GAA technology featuring multi-bridge-channel FET for low power and high performance applications,'' in IEDM Tech. Dig. , Dec. 2018, pp. 28.7.1GLYPH<21>28.7.4.\n- [10] X. Jiang, X. Wang, R. Wang, B. Cheng, A. Asenov, and R. Huang, ''Predictive compact modeling of random variations in FinFET technology for 16/14 nm node and beyond,'' in IEDM Tech. Dig. , Dec. 2015, pp. 28.3.1GLYPH<21>28.3.4.\n- [11] M. H. A. Banna, K. A. Taher, M. S. Kaiser, M. Mahmud, M. S. Rahman, A. S. M. S. Hosen, and G. H. Cho, ''Application of artiGLYPH<28>cial intelligence in predicting earthquakes: State-of-the-art and future challenges,'' IEEE Access , vol. 8, pp. 192880GLYPH<21>192923, 2020.\n- [12] M. B. T. Noor, N. Z. Zenia, M. S. Kaiser, S. A. Mamun, and M. Mahmud, ''Application of deep learning in detecting neurological disorders from magnetic resonance images: A survey on the detection of Alzheimer's disease, Parkinson's disease and schizophrenia,'' Brain Informat. , vol. 7, no. 1, pp. 1GLYPH<21>21, Dec. 2020.\n- [13] A. Whata and C. Chimedza, ''Deep learning for SARS COV-2 genome sequences,'' IEEE Access , vol. 9, pp. 59597GLYPH<21>59611, 2021.\n- [14] H.-C. Choi, H. Yun, J.-S. Yoon, and R.-H. Baek, ''Neural approach for modeling and optimizing Si-MOSFET manufacturing,'' IEEE Access , vol. 8, pp. 159351GLYPH<21>159370, 2020.\n- [15] D. Jiang, W. Lin, and N. Raghavan, ''A Gaussian mixture model clustering ensemble regressor for semiconductor manufacturing GLYPH<28>nal test yield prediction,'' IEEE Access , vol. 9, pp. 22253GLYPH<21>22263, 2021.\n- [16] J.-S. Yoon, S. Lee, H. Yun, and R.-H. Baek, ''Digital/analog performance optimization of vertical nanowire FETs using machine learning,'' IEEE Access , vol. 9, pp. 29071GLYPH<21>29077, 2021.\n- [17] K. Ko, J. K. Lee, and H. Shin, ''Variability-aware machine learning strategy for 3-D NAND GLYPH<29>ash memories,'' IEEE Trans. Electron Devices , vol. 67, no. 4, pp. 1575GLYPH<21>1580, Apr. 2020.\n- [18] J. Lim and C. Shin, ''Machine learning (ML)-based model to characterize the line edge roughness (LER)-induced random variation in FinFET,'' IEEE Access , vol. 8, pp. 158237GLYPH<21>158242, 2020.\n- [19] S. Oh and C. Shin, ''3-D quasi-atomistic model for line edge roughness in nonplanar MOSFETs,'' IEEE Trans. Electron Devices , vol. 63, no. 12, pp. 4617GLYPH<21>4623, Dec. 2016.\n- [20] TCAD Sentaurus? User Guide Version P-2019.03 , Synopsys, Inc., Mountain View, CA, USA, 2019.\n- [21] C. Shin, Variation-Aware Advanced CMOS Devices and SRAM , vol. 56. Dordrecht, The Netherlands: Springer, 2016.\n- [22] E. Dornel, T. Ernst, J. C. Barb, J. M. Hartmann, V. Delaye, F. Aussenac, C. Vizioz, S. Borel, V . MafGLYPH<28>ni-Alvaro, C. Isheden, and J. Foucher, ''Hydrogen annealing of arrays of planar and vertically stacked Si nanowires,'' Appl. Phys. Lett. , vol. 91, no. 23, Dec. 2007, Art. no. 233502.\n- [23] T. Tezuka, N. Hirashita, Y. Moriyama, N. Sugiyama, K. Usuda, E. Toyoda, K. Murayama, and S.-I. Takagi, ''110-facets formation by hydrogen thermal etching on sidewalls of Si and strained-Si GLYPH<28>n structures,'' Appl. Phys. Lett. , vol. 92, no. 19, May 2008, Art. no. 191903.\n- [24] Y. Ma, H. J. Levinson, and T. Wallow, ''Line edge roughness impact on critical dimension variation,'' Proc. SPIE , vol. 6518, Apr. 2007, Art. no. 651824.\n- [25] Y. Rubner, C. Tomasi, and L. J. Guibas, ''A metric for distributions with applications to image databases,'' in Proc. 6th Int. Conf. Comput. Vis. , Jan. 1998, pp. 59GLYPH<21>66.",
        "context": "Provides supporting evidence for the argument on economic inequality; Introduces the central thesis about climate policy reform; Transitions from background information to proposed methodology; Introduces the simple ANN model and its purpose.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            8
        ],
        "id": "2b7d8670415464bdf257d5c221314de4374991de560e9fe9aee483222951ecd2"
    },
    {
        "text": "Provides a detailed analysis of line edge roughness and its impact on MOSFETs, including statistical fluctuations and methods for mitigating variation in SRAM devices.\n\n- [26] A. Asenov, S. Kaya, and A. R. Brown, ''Intrinsic parameter GLYPH<29>uctuations in decananometer MOSFETs introduced by gate line edge roughness,'' IEEE Trans. Electron Devices , vol. 50, no. 5, pp. 1254GLYPH<21>1260, May 2003.\n- [27] J. Min and C. Shin, ''Study of line edge roughness on various types of gateall-around GLYPH<28>eld effect transistor,'' Semicond. Sci. Technol. , vol. 35, no. 1, Jan. 2020, Art. no. 015004.\n- [28] Y.-N. Chen, C.-J. Chen, M.-L. Fan, V. Hu, P. Su, and C.-T. Chuang, ''Impacts of work function variation and line-edge roughness on TFET and FinFET devices and 32-bit CLA circuits,'' J. Low Power Electron. Appl. , vol. 5, no. 2, pp. 101GLYPH<21>115, May 2015.\n- [29] S. Kaya, A. Brown, A. Asenov, D. Magot, and T. LintonI, ''Analysis of statistical GLYPH<29>uctuations due to line edge roughness in sub-0.1 GLYPH<22> mMOSFETs,'' in Simulation of Semiconductor Processes and Devices . Vienna, Austria: Springer, 2001, pp. 78GLYPH<21>81.\n- [30] J.-X. Pan and K.-T. Fang, ''Maximum likelihood estimation,'' in Growth Curve Models and Statistical Diagnostics . New York, NY, USA: Springer, 2002, pp. 77GLYPH<21>158.\n- [31] D. P. Kingma and J. Ba, ''Adam: A method for stochastic optimization,'' 2014, arXiv:1412.6980 . [Online]. Available: \n- [32] M. Abadi et al. , ''TensorFlow: Large-scale machine learning on heterogeneous distributed systems,'' 2016, arXiv:1603.04467 . [Online]. Available: \n- [33] M. Abadi et al. , ''TensorFlow: A system for large-scale machine learning,'' in Proc. 12th USENIX Symp. Operating Syst. Design Implement. (OSDI) , 2016, pp. 265GLYPH<21>283.\n- [34] A. E. Carlson, ''Device and circuit techniques for reducing variation in nanoscale SRAM,'' Univ, California, Berkeley, CA, USA, Tech. Rep., 2008, pp. 23GLYPH<21>51.\nJAEHYUK LIM received the B.S. degree in electronic and electrical engineering from Sungkyunkwan University (SKKU), Suwon, Republic of Korea, in 2020, where he is currently pursuing the M.S. degree in electrical and computer engineering. His current research interests include machine learning and process induced random variations.\nJINWOONG LEE received the B.S. degree from the Department of Physics, KyungHee University (KHU), Seoul, Republic of Korea, in 2017. He is currently pursuing the M.S. degree in electrical and computer engineering with Sungkyunkwan University (SKKU). His current research interests include machine learning and process induced random variations.\nCHANGHWAN SHIN (Senior Member, IEEE) received the B.S. degree (Hons.) in electrical engineering from Korea University, Seoul, Republic of Korea, in 2006, and the Ph.D. degree in electrical engineering and computer sciences from the University of California at Berkeley, in 2011. Since 2017, he has been with the Board of Directors in SK Hynix. He is currently with the Department of Electrical and Computer Engineering, Sungkyunkwan University. His current research interests include advanced CMOS device designs and their applications to memory/logic devices.",
        "original_text": "- [26] A. Asenov, S. Kaya, and A. R. Brown, ''Intrinsic parameter GLYPH<29>uctuations in decananometer MOSFETs introduced by gate line edge roughness,'' IEEE Trans. Electron Devices , vol. 50, no. 5, pp. 1254GLYPH<21>1260, May 2003.\n- [27] J. Min and C. Shin, ''Study of line edge roughness on various types of gateall-around GLYPH<28>eld effect transistor,'' Semicond. Sci. Technol. , vol. 35, no. 1, Jan. 2020, Art. no. 015004.\n- [28] Y.-N. Chen, C.-J. Chen, M.-L. Fan, V. Hu, P. Su, and C.-T. Chuang, ''Impacts of work function variation and line-edge roughness on TFET and FinFET devices and 32-bit CLA circuits,'' J. Low Power Electron. Appl. , vol. 5, no. 2, pp. 101GLYPH<21>115, May 2015.\n- [29] S. Kaya, A. Brown, A. Asenov, D. Magot, and T. LintonI, ''Analysis of statistical GLYPH<29>uctuations due to line edge roughness in sub-0.1 GLYPH<22> mMOSFETs,'' in Simulation of Semiconductor Processes and Devices . Vienna, Austria: Springer, 2001, pp. 78GLYPH<21>81.\n- [30] J.-X. Pan and K.-T. Fang, ''Maximum likelihood estimation,'' in Growth Curve Models and Statistical Diagnostics . New York, NY, USA: Springer, 2002, pp. 77GLYPH<21>158.\n- [31] D. P. Kingma and J. Ba, ''Adam: A method for stochastic optimization,'' 2014, arXiv:1412.6980 . [Online]. Available: \n- [32] M. Abadi et al. , ''TensorFlow: Large-scale machine learning on heterogeneous distributed systems,'' 2016, arXiv:1603.04467 . [Online]. Available: \n- [33] M. Abadi et al. , ''TensorFlow: A system for large-scale machine learning,'' in Proc. 12th USENIX Symp. Operating Syst. Design Implement. (OSDI) , 2016, pp. 265GLYPH<21>283.\n- [34] A. E. Carlson, ''Device and circuit techniques for reducing variation in nanoscale SRAM,'' Univ, California, Berkeley, CA, USA, Tech. Rep., 2008, pp. 23GLYPH<21>51.\nJAEHYUK LIM received the B.S. degree in electronic and electrical engineering from Sungkyunkwan University (SKKU), Suwon, Republic of Korea, in 2020, where he is currently pursuing the M.S. degree in electrical and computer engineering. His current research interests include machine learning and process induced random variations.\nJINWOONG LEE received the B.S. degree from the Department of Physics, KyungHee University (KHU), Seoul, Republic of Korea, in 2017. He is currently pursuing the M.S. degree in electrical and computer engineering with Sungkyunkwan University (SKKU). His current research interests include machine learning and process induced random variations.\nCHANGHWAN SHIN (Senior Member, IEEE) received the B.S. degree (Hons.) in electrical engineering from Korea University, Seoul, Republic of Korea, in 2006, and the Ph.D. degree in electrical engineering and computer sciences from the University of California at Berkeley, in 2011. Since 2017, he has been with the Board of Directors in SK Hynix. He is currently with the Department of Electrical and Computer Engineering, Sungkyunkwan University. His current research interests include advanced CMOS device designs and their applications to memory/logic devices.",
        "context": "Provides a detailed analysis of line edge roughness and its impact on MOSFETs, including statistical fluctuations and methods for mitigating variation in SRAM devices.",
        "document": "Probabilistic_Artificial_Neural_Network_for_Line-Edge-Roughness-Induced_Random_Variation_in_FinFET.pdf",
        "pages": [
            8,
            9
        ],
        "id": "45beae817a02ee8e490f9a85fc71649360380151026655acda52f6ddf6fc0da2"
    }
]